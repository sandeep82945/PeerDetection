[
    {
        "title": "CONCEPT BOTTLENECK GENERATIVE MODELS",
        "abstract": "We introduce a generative model with an intrinsically interpretable layer\u2014a concept bottleneck layer\u2014that constrains the model to encode human-understandable concepts. The concept bottleneck layer partitions the generative model into three parts: the pre-concept bottleneck portion, the CB layer, and the post-concept bottleneck portion. To train CB generative models, we complement the traditional task-based loss function for training generative models with a concept loss and an orthogonality loss. The CB layer and these loss terms are model agnostic, which we demonstrate by applying the CB layer to three different families of generative models: generative adversarial networks, variational autoencoders, and diffusion models. On multiple datasets across different types of generative models, steering a generative model, with the CB layer, outperforms all baselines\u2014in some cases, it is 10 times more effective. In addition, we show how the CB layer can be used to interpret the output of the generative model and debug the model during or post training.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper introduces concept bottleneck generative models (CBGMs), a novel approach to generative modeling that incorporates an intrinsically interpretable layer, the concept bottleneck (CB) layer. This layer is designed to constrain the model to encode human-understandable concepts, enabling the model to be steered, interpreted, and debugged. The CB layer is model-agnostic, meaning it can be applied to various generative model families, including variational autoencoders (VAEs), generative adversarial networks (GANs), and diffusion models. The authors demonstrate the effectiveness of CBGMs in steering generative models, interpreting their output, and debugging them during and post-training.\n\nStrengths:\n\n1. The paper presents a novel and innovative approach to generative modeling, addressing a significant limitation of current generative models, which are largely inscrutable and difficult to steer.\n2. The concept bottleneck layer is model-agnostic, allowing it to be applied to various generative model families, increasing its versatility and potential impact.\n3. The authors provide a comprehensive evaluation of CBGMs, including steering, interpretation, and debugging experiments, which demonstrate their effectiveness and robustness.\n4. The paper discusses the limitations of current approaches to interpreting and steering generative models, highlighting the need for more interpretable and controllable models.\n\nWeaknesses:\n\n1. The paper requires a significant amount of background knowledge in generative modeling, which may make it challenging for readers without a strong foundation in the field.\n2. The authors rely heavily on existing work, which may make it difficult to distinguish the novelty and contributions of the paper.\n3. The paper does not provide a clear explanation of how the concept bottleneck layer is trained, which is a critical aspect of the method.\n4. The authors do not discuss the potential limitations and challenges of applying the concept bottleneck layer to more complex and realistic settings.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed explanation of the training process for the concept bottleneck layer, including the loss functions and hyperparameters used.\n2. Discuss the potential limitations and challenges of applying the concept bottleneck layer to more complex and realistic settings, such as text or 3D data.\n3. Provide more qualitative and quantitative evaluations of the concept bottleneck layer, including its performance on more challenging tasks and datasets.\n4. Consider incorporating more visualizations and illustrations to help readers understand the concept bottleneck layer and its applications.\n\nRecommendation:\n\nThis paper presents a novel and innovative approach to generative modeling, addressing a significant limitation of current generative models. The concept bottleneck layer is model-agnostic, allowing it to be applied to various generative model families, increasing its versatility and potential impact. While the paper has some limitations, it provides a comprehensive evaluation of CBGMs and demonstrates their effectiveness and robustness. I recommend this paper to readers interested in generative modeling, interpretability, and controllability.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThis paper proposes a novel generative model architecture, called concept bottleneck generative models (CBGMs), which integrates a concept bottleneck (CB) layer to enable interpretability, steerability, and debuggability. The CB layer is a plug-in module that can be applied to various generative models, including generative adversarial networks (GANs), variational autoencoders (VAEs), and diffusion models. The CB layer constrains the model to encode human-understandable concepts, which can be used to steer the model's output and debug the model during and post-training.\n\nStrengths:\n\n1. The CBGM architecture is flexible and can be applied to various generative models, making it a versatile tool for generative modeling.\n2. The CB layer enables interpretability, steerability, and debuggability, which are essential for understanding and controlling the model's behavior.\n3. The paper provides a comprehensive evaluation of the CBGM architecture, including experiments on multiple datasets and generative models.\n4. The authors provide a clear and well-organized presentation of the paper, making it easy to follow and understand.\n\nWeaknesses:\n\n1. The paper assumes that the training set is annotated with pre-defined concepts, which may not be feasible in practice, especially for large-scale datasets.\n2. The CB layer requires a large number of concepts to be defined, which can be time-consuming and labor-intensive.\n3. The paper does not provide a detailed analysis of the computational complexity of the CBGM architecture.\n4. The authors do not provide a clear comparison with existing state-of-the-art generative models.\n\nSuggestions for Improvement:\n\n1. The authors should provide a more detailed analysis of the computational complexity of the CBGM architecture and its implications for large-scale datasets.\n2. The paper should include a more thorough evaluation of the CBGM architecture on a wider range of datasets and generative models.\n3. The authors should provide a more detailed comparison with existing state-of-the-art generative models, including a discussion of the strengths and weaknesses of each approach.\n4. The paper should include a more detailed discussion of the potential applications of the CBGM architecture, including its potential uses in real-world settings.\n\nRecommendation:\n\nThis paper presents a novel and innovative generative model architecture that enables interpretability, steerability, and debuggability. The CBGM architecture is flexible and can be applied to various generative models, making it a valuable tool for generative modeling. However, the paper assumes that the training set is annotated with pre-defined concepts, which may not be feasible in practice. The authors should provide a more detailed analysis of the computational complexity of the CBGM architecture and its implications for large-scale datasets. With these improvements, the CBGM architecture has the potential to become a leading approach in generative modeling.\n\nRating: 8/10\n\nReviewer's Expertise: Generative modeling, deep learning, and computer vision.\n\nReviewer's Comments:\n\nThis paper presents a novel and innovative generative model architecture that enables interpretability, steerability, and debuggability. The CBGM architecture is flexible and can be applied to various generative models, making it a valuable tool for generative modeling. However, the paper assumes that the training set is annotated with pre-defined concepts, which may not be feasible in practice. The authors should provide a more detailed analysis of the computational complexity of the CBGM architecture and its implications for large-scale datasets. With these improvements, the CBGM architecture has the potential to become a leading approach in generative modeling.\n\n$$$",
        "gr_score_with": 0.9565217391304348,
        "gr_score_without": 0.9254498714652957,
        "output_without": {
            "num_tokens_scored": 389,
            "num_green_tokens": 360,
            "green_fraction": 0.9254498714652957,
            "z_score": 1.6733482620544442,
            "p_value": 0.04712937834371358
        },
        "output_with": {
            "num_tokens_scored": 345,
            "num_green_tokens": 330,
            "green_fraction": 0.9565217391304348,
            "z_score": 3.4996269497977806,
            "p_value": 0.0002329548461106293
        }
    },
    {
        "title": "SWAP: SPARSE ENTROPIC WASSERSTEIN REGRESSION FOR ROBUST NETWORK PRUNING",
        "abstract": "This study addresses the challenge of inaccurate gradients in computing the empirical Fisher Information Matrix during neural network pruning. We introduce SWAP, a formulation of Entropic Wasserstein regression (EWR) for pruning, capitalizing on the geometric properties of the optimal transport problem. The \u201cswap\u201d of the commonly used linear regression with the EWR in optimization is analytically demonstrated to offer noise mitigation effects by incorporating neighborhood interpolation across data points with only marginal additional computational cost. The unique strength of SWAP is its intrinsic ability to balance noise reduction and covariance information preservation effectively. Extensive experiments performed on various networks and datasets show comparable performance of SWAP with state-of-the-art (SoTA) network pruning algorithms. Our proposed method outperforms the SoTA when the network size or the target sparsity is large, the gain is even larger with the existence of noisy gradients, possibly from noisy data, analog memory, or adversarial attacks. Notably, our proposed method achieves a gain of 6% improvement in accuracy and 8% improvement in testing loss for MobileNetV1 with less than one-fourth of the network parameters remaining.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel method for neural network pruning called Sparse Entropic Wasserstein Regression Pruning (SWAP), which leverages the Entropic Wasserstein regression (EWR) to mitigate the effect of noisy gradients in computing the empirical Fisher Information Matrix (FIM). The proposed method, SWAP, is shown to outperform state-of-the-art (SoTA) network pruning algorithms, especially in the presence of noisy gradients.\n\nStrengths:\n\n1. The paper provides a comprehensive analysis of the network pruning problem and its relation to the optimization problem, which is a significant contribution to the field.\n2. The proposed method, SWAP, is shown to be robust to noisy gradients, which is a critical aspect of neural network pruning.\n3. The paper provides a thorough comparison of SWAP with other SoTA methods, including magnitude pruning, WoodFisher, and Combinatorial Brain Surgeon.\n4. The authors provide a clear and concise algorithmic framework for SWAP, which is easy to implement and understand.\n\nWeaknesses:\n\n1. The paper assumes that the neural network is pre-trained, which may not be the case in practice.\n2. The proposed method requires the computation of the Wasserstein distance, which can be computationally expensive for large datasets.\n3. The paper does not provide a thorough analysis of the computational complexity of SWAP.\n4. The authors do not provide a clear explanation of how to choose the regularization parameter \u03bb and the entropic regularization term \u03b5.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed analysis of the computational complexity of SWAP and its scalability to large datasets.\n2. Investigate the effect of different regularization parameters \u03bb and entropic regularization terms \u03b5 on the performance of SWAP.\n3. Provide a more comprehensive comparison of SWAP with other SoTA methods, including a more detailed analysis of their strengths and weaknesses.\n4. Investigate the applicability of SWAP to other machine learning tasks, such as clustering and dimensionality reduction.\n\nRecommendation:\n\nThe paper provides a novel and robust method for neural network pruning, which has the potential to improve the performance of neural networks in the presence of noisy gradients. However, the paper requires further investigation and improvement in terms of computational complexity, scalability, and applicability to other machine learning tasks. Therefore, I recommend that the authors provide a more detailed analysis of the computational complexity of SWAP and its scalability to large datasets, and investigate the effect of different regularization parameters \u03bb and entropic regularization terms \u03b5 on the performance of SWAP.\n\nOverall, I believe that the paper provides a significant contribution to the field of neural network pruning and has the potential to improve the performance of neural networks in the presence of noisy gradients.\n\nRating: 7.5/10\n\nRecommendation: Accept with minor revisions.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel method called SWAP (Sparse Entropic Wasserstein Regression) for neural network pruning. The method aims to address the challenge of inaccurate gradients in computing the empirical Fisher Information Matrix during neural network pruning. The authors introduce a formulation of Entropic Wasserstein regression (EWR) for pruning, which capitalizes on the geometric properties of the optimal transport problem. The proposed method, SWAP, is demonstrated to offer noise mitigation effects by incorporating neighborhood interpolation across data points with only marginal additional computational cost.\n\nStrengths:\n\n1. The paper provides a novel formulation of Entropic Wasserstein regression (EWR) for pruning, which strikes a balance between covariance information preservation and noise reduction.\n2. The authors demonstrate the effectiveness of the proposed method, SWAP, in addressing the challenge of inaccurate gradients in computing the empirical Fisher Information Matrix during neural network pruning.\n3. The paper provides extensive experimental results, including comparisons with state-of-the-art (SoTA) methods, which demonstrate the superiority of the proposed method in terms of robustness against noise.\n4. The authors provide a clear and concise explanation of the proposed method, including the mathematical formulation and the algorithmic framework.\n\nWeaknesses:\n\n1. The paper assumes a fixed number of pruning stages T, which may not be optimal in practice. It would be beneficial to investigate the impact of varying T on the performance of the proposed method.\n2. The authors do not provide a comprehensive analysis of the computational complexity of the proposed method, which is an important aspect to consider in practice.\n3. The paper assumes a fixed regularization parameter \u03bb, which may not be optimal in practice. It would be beneficial to investigate the impact of varying \u03bb on the performance of the proposed method.\n\nSuggestions for Improvement:\n\n1. Investigate the impact of varying the number of pruning stages T on the performance of the proposed method.\n2. Provide a comprehensive analysis of the computational complexity of the proposed method.\n3. Investigate the impact of varying the regularization parameter \u03bb on the performance of the proposed method.\n4. Consider incorporating additional techniques, such as early stopping or warm restarts, to further improve the performance of the proposed method.\n\nRecommendation:\n\nThe proposed method, SWAP, is a novel and effective approach to neural network pruning that addresses the challenge of inaccurate gradients in computing the empirical Fisher Information Matrix. The method is demonstrated to offer noise mitigation effects and strikes a balance between covariance information preservation and noise reduction. While there are some weaknesses and suggestions for improvement, the proposed method has the potential to be a valuable tool in the field of neural network pruning. Therefore, I recommend accepting this paper for publication.\n\nRating: 8/10\n\nReviewer's Signature: [Your Name]\n\nDate: [Today's Date]\n\n$$$",
        "gr_score_with": 0.911504424778761,
        "gr_score_without": 0.898876404494382,
        "output_without": {
            "num_tokens_scored": 356,
            "num_green_tokens": 320,
            "green_fraction": 0.898876404494382,
            "z_score": -0.07046939958061729,
            "p_value": 0.5280899722101721
        },
        "output_with": {
            "num_tokens_scored": 339,
            "num_green_tokens": 309,
            "green_fraction": 0.911504424778761,
            "z_score": 0.70624469965885,
            "p_value": 0.24001798847950157
        }
    },
    {
        "title": "BEYOND IMITATION: LEVERAGING FINE-GRAINED QUALITY SIGNALS FOR ALIGNMENT",
        "abstract": "Alignment with human preference is a desired property of large language models (LLMs). Currently, the main alignment approach is based on reinforcement learning from human feedback (RLHF). Despite the effectiveness of RLHF, it is intricate to implement and train, thus recent studies explore how to develop alternative alignment approaches based on supervised fine-tuning (SFT). A major limitation of SFT is that it essentially does imitation learning, which cannot fully understand what are the expected behaviors. To address this issue, we propose an improved alignment approach named FIGA. Different from prior methods, we incorporate fine-grained (i.e., token or phrase level) quality signals that are derived by contrasting good and bad responses. Our approach has made two major contributions. Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones. Secondly, we devise a new loss function can leverage fine-grained quality signals to instruct the learning of LLMs for alignment. Extensive experiments have demonstrated the effectiveness of our approaches by comparing a number of competitive baselines. We release all the above-mentioned resources at https://github.com/RUCAIBox/FIGA.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel approach called FIGA (Fine-grained Quality-Aware Alignment) for aligning language models with human preferences. The approach leverages fine-grained quality signals derived by contrasting good and bad responses to instruct the learning of language models for alignment. The authors curate a refined alignment dataset called SPA (SubPar Alignment) that pairs initial responses with revised responses on queries where a language model performs less well. They also design a new loss function that incorporates fine-grained quality signals to encourage the model to learn good behaviors and penalize bad behaviors. The approach is evaluated on several benchmarks, showing superior performance compared to existing alignment methods.\n\nStrengths:\n\n1. The paper presents a novel approach for aligning language models with human preferences, which is a critical problem in natural language processing.\n2. The approach leverages fine-grained quality signals, which provides more detailed information about what makes a response good or bad.\n3. The authors curate a refined alignment dataset called SPA, which is a significant contribution to the field.\n4. The approach is evaluated on several benchmarks, showing superior performance compared to existing alignment methods.\n\nWeaknesses:\n\n1. The paper assumes the availability of a reward model, which may not always be the case in real-world scenarios.\n2. The approach relies on the quality of the revised responses, which may not always be available or reliable.\n3. The paper does not provide a detailed analysis of the Levenshtein distance metric used to quantify the similarity between initial and revised responses.\n4. The approach may not generalize well to out-of-distribution scenarios, where the reward model may not perform well.\n\nSuggestions for Improvement:\n\n1. Investigate alternative methods for deriving fine-grained quality signals, such as using other metrics or incorporating additional information.\n2. Evaluate the approach on more diverse and challenging datasets to assess its generalizability.\n3. Provide more detailed analysis of the Levenshtein distance metric and its limitations.\n4. Investigate the use of other reward models or alternative methods for aligning language models with human preferences.\n\nRecommendation:\n\nThe paper presents a novel and promising approach for aligning language models with human preferences. While there are some limitations and areas for improvement, the approach shows superior performance compared to existing alignment methods. I recommend this paper for publication in a top-tier conference, with the suggestion to address the weaknesses and improve the approach as mentioned above.\n\nRating: 8/10\n\n$$$",
        "peer_review_with_watermark": "$$$ \nPaper Summary:\n\nThe paper proposes an alignment approach named FIGA, which leverages fine-grained quality signals to improve the alignment of large language models (LLMs) with human preferences. FIGA consists of two main components: a curated alignment dataset called SPA and a new loss function that incorporates fine-grained quality signals. The SPA dataset pairs initial responses with revised responses on queries where the LLM performs less well, and the new loss function assigns different weights to different parts of the responses based on their quality. The authors demonstrate the effectiveness of FIGA by comparing it with several competitive baselines on various tasks, including knowledge utilization, human alignment, and open-ended generation.\n\nStrengths:\n\n* The paper presents a novel approach to aligning LLMs with human preferences by leveraging fine-grained quality signals.\n* The proposed FIGA method has several advantages over traditional SFT and RLHF methods, including ease of implementation, efficient training, and better understanding of correct behaviors for alignment.\n* The authors provide extensive experimental results and comparisons with competitive baselines, demonstrating the effectiveness of FIGA on various tasks.\n* The paper provides detailed implementation details and hyperparameter settings, making it easier for readers to reproduce the results.\n\nWeaknesses:\n\n* The paper assumes the availability of a reward model for assessing the alignment level, which may not be feasible in all scenarios.\n* The construction of the SPA dataset requires careful filtering and revision of initial responses, which may be time-consuming and labor-intensive.\n* The paper does not provide a thorough analysis of the trade-offs between the different components of the FIGA method, such as the importance of fine-grained quality signals and the impact of different hyperparameters.\n* The paper does not discuss potential limitations and challenges of the FIGA method, such as its applicability to diverse domains and tasks.\n\nSuggestions for Improvement:\n\n* Provide more detailed analysis of the trade-offs between the different components of the FIGA method, including the importance of fine-grained quality signals and the impact of different hyperparameters.\n* Discuss potential limitations and challenges of the FIGA method, such as its applicability to diverse domains and tasks.\n* Provide more information on the construction of the SPA dataset, including the filtering and revision process, and the impact of different hyperparameters on the quality of the dataset.\n* Consider evaluating the FIGA method on more diverse tasks and domains to demonstrate its generalizability and robustness.\n\nRecommendation:\n\nThis paper presents a novel and effective approach to aligning LLMs with human preferences by leveraging fine-grained quality signals. The proposed FIGA method has several advantages over traditional SFT and RLHF methods, including ease of implementation, efficient training, and better understanding of correct behaviors for alignment. However, the paper assumes the availability of a reward model for assessing the alignment level, which may not be feasible in all scenarios. The construction of the SPA dataset requires careful filtering and revision of initial responses, which may be time-consuming and labor-intensive. Overall, the paper provides valuable insights and contributions to the field of language model alignment and is recommended for publication in the conference.",
        "gr_score_with": 0.9438502673796791,
        "gr_score_without": 0.9034090909090909,
        "output_without": {
            "num_tokens_scored": 352,
            "num_green_tokens": 318,
            "green_fraction": 0.9034090909090909,
            "z_score": 0.21339280241665434,
            "p_value": 0.41551029703127207
        },
        "output_with": {
            "num_tokens_scored": 374,
            "num_green_tokens": 353,
            "green_fraction": 0.9438502673796791,
            "z_score": 2.826907901475086,
            "p_value": 0.002349992156851359
        }
    },
    {
        "title": "GUAGE MODEL POWERED DIALOGUE AGENTS",
        "abstract": "Proactive dialogues serve as a practical yet challenging dialogue problem in the era of large language models (LLMs), where the dialogue policy planning is the key to improving the proactivity of LLMs. Most existing studies enable the dialogue policy planning of LLMs using various prompting schemes or iteratively enhance this capability in handling the given case with verbal AI feedback. However, these approaches are either bounded by the policy planning capability of the frozen LLMs or hard to be transferred to new cases. In this work, we introduce a new dialogue policy planning paradigm to strategize LLMs for proactive dialogue problems with a tunable language model plug-in as a plug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a novel training framework to facilitate supervised fine-tuning over available human-annotated data as well as reinforcement learning from goal-oriented AI feedback with dynamic interaction data collected by the LLM-based self-play simulation. In this manner, the LLM-powered dialogue agent can not only be generalized to different cases after the training, but also be applicable to different applications by just substituting the learned plug-in. In addition, we propose to evaluate the policy planning capability of dialogue systems under the interactive setting. Experimental results demonstrate that PPDPP consistently and substantially outperforms existing approaches on three different proactive dialogue applications, including negotiation, emotional support, and tutoring dialogues.1",
        "peer_review_without_watermark": "$$$\nPaper Summary:\nThe paper proposes a novel paradigm for strategizing large language models (LLMs) powered dialogue agents, called Plug-and-Play Dialogue Policy Planner (PPDPP). PPDPP is designed to tackle the challenges of proactive dialogue problems, where the dialogue agent needs to strategically take the initiative to steer the conversation towards an anticipated goal. The proposed framework consists of a tunable language model plug-in that can be fine-tuned with available human-annotated data and reinforced learning from goal-oriented AI feedback. The authors demonstrate the effectiveness of PPDPP on three different proactive dialogue problems, including negotiation, emotional support, and tutoring dialogues.\n\nStrengths:\n1. The paper proposes a novel and effective approach to tackle the challenges of proactive dialogue problems.\n2. The framework is designed to be modular and flexible, allowing for easy adaptation to different applications and domains.\n3. The authors provide a thorough evaluation of PPDPP on three different datasets, demonstrating its superiority over existing approaches.\n4. The paper highlights the potential of tunable plug-ins to address specific shortcomings in LLMs and integrate with multiple plug-ins to tackle more complex dialogue challenges.\n\nWeaknesses:\n1. The paper assumes the availability of human-annotated data, which may not be feasible in all scenarios.\n2. The framework relies on the quality of the goal-oriented AI feedback, which may not always be available or reliable.\n3. The paper does not provide a detailed analysis of the computational resources required for training and deploying PPDPP.\n4. The authors do not discuss the potential limitations and biases of using LLMs in dialogue systems.\n\nSuggestions for Improvement:\n1. Provide more detailed information on the data requirements and preprocessing steps for training PPDPP.\n2. Discuss the potential limitations and biases of using LLMs in dialogue systems and propose potential solutions.\n3. Provide a more comprehensive analysis of the computational resources required for training and deploying PPDPP.\n4. Consider exploring other types of goal-oriented AI feedback, such as multi-modal feedback, to improve the robustness of PPDPP.\n\nRecommendation:\nThe paper proposes a novel and effective approach to tackle the challenges of proactive dialogue problems. While there are some limitations and areas for improvement, the framework shows promise for a wide range of applications. I recommend the paper for publication, with the understanding that the authors will address the suggested improvements in future work.\n\nGrade: B+ (87%)\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\nThe paper proposes a novel paradigm for strategizing large language models (LLMs) powered dialogue agents, called Plug-and-Play Dialogue Policy Planner (PPDPP). PPDPP utilizes a tunable language model plug-in to facilitate supervised fine-tuning and reinforcement learning from goal-oriented AI feedback, enabling the LLM-powered dialogue agent to generalize to different cases and exhibit versatility across diverse applications.\n\nStrengths:\n1. The paper proposes a novel and effective approach to improving the policy planning capability of LLM-powered dialogue agents.\n2. The proposed framework can be generalized to different cases and exhibits versatility across diverse applications.\n3. The experimental results demonstrate the superiority of PPDPP over existing approaches on three different proactive dialogue problems.\n4. The paper provides a comprehensive evaluation of the proposed method, including both automatic and human evaluation.\n\nWeaknesses:\n1. The paper relies heavily on the quality of the pre-trained language model and the human-annotated corpus.\n2. The proposed framework requires a significant amount of computational resources and data to train.\n3. The paper does not provide a clear explanation of how the tunable language model plug-in is learned and updated during the reinforcement learning process.\n4. The paper only evaluates the proposed method on three specific proactive dialogue problems, and it is unclear how well the method would generalize to other domains.\n\nSuggestions for Improvement:\n1. Provide a more detailed explanation of how the tunable language model plug-in is learned and updated during the reinforcement learning process.\n2. Evaluate the proposed method on a wider range of proactive dialogue problems to demonstrate its generalizability.\n3. Provide a clearer explanation of the role of the pre-trained language model and the human-annotated corpus in the proposed framework.\n4. Consider incorporating additional evaluation metrics, such as turn-level response quality measurements, to provide a more comprehensive evaluation of the proposed method.\n\nRecommendation:\nThe proposed method has the potential to significantly improve the policy planning capability of LLM-powered dialogue agents, making it a valuable contribution to the field of conversational AI research. However, further evaluation and refinement of the method are necessary to demonstrate its robustness and generalizability across different domains and applications.\n\nRating: 8/10\n$$$",
        "gr_score_with": 0.9221183800623053,
        "gr_score_without": 0.9052924791086351,
        "output_without": {
            "num_tokens_scored": 359,
            "num_green_tokens": 325,
            "green_fraction": 0.9052924791086351,
            "z_score": 0.33445288670240736,
            "p_value": 0.3690189184315381
        },
        "output_with": {
            "num_tokens_scored": 321,
            "num_green_tokens": 296,
            "green_fraction": 0.9221183800623053,
            "z_score": 1.3211124662893212,
            "p_value": 0.09323193348841963
        }
    },
    {
        "title": "THE EFFECTIVENESS OF RANDOM FORGETTING FOR ROBUST GENERALIZATION",
        "abstract": "Deep neural networks are susceptible to adversarial attacks, which can compromise their performance and accuracy. Adversarial Training (AT) has emerged as a popular approach for protecting neural networks against such attacks. However, a key challenge of AT is robust overfitting, where the network\u2019s robust performance on test data deteriorates with further training, thus hindering generalization. Motivated by the concept of active forgetting in the brain, we introduce a novel learning paradigm called \u201cForget to Mitigate Overfitting (FOMO)\". FOMO alternates between the forgetting phase, which randomly forgets a subset of weights and regulates the model\u2019s information through weight reinitialization, and the relearning phase, which emphasizes learning generalizable features. Our experiments on benchmark datasets and adversarial attacks show that FOMO alleviates robust overfitting by significantly reducing the gap between the best and last robust test accuracy while improving the state-of-the-art robustness. Furthermore, FOMO provides a better trade-off between standard and robust accuracy, outperforming baseline adversarial methods. Finally, our framework is robust to AutoAttacks and increases generalization in many real-world scenarios.1",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel adversarial training paradigm called Forget to Mitigate Overfitting (FOMO) to address the problem of robust overfitting in deep neural networks (DNNs). FOMO alternates between the forgetting phase, where a subset of weights is randomly forgotten through reinitialization, and the relearning phase, where the network emphasizes learning generalizable features. The authors demonstrate the efficacy of FOMO on benchmark datasets and adversarial attacks, showing that it alleviates robust overfitting, improves robustness, and provides a better trade-off between standard and robust accuracy.\n\nStrengths:\n\n1. The paper provides a comprehensive overview of the problem of robust overfitting in adversarial training and its significance in real-world applications.\n2. The authors propose a novel and innovative solution, FOMO, which is grounded in the concept of active forgetting and relearning, inspired by the human brain's learning mechanisms.\n3. The experimental results demonstrate the effectiveness of FOMO in alleviating robust overfitting, improving robustness, and providing a better trade-off between standard and robust accuracy.\n4. The authors conduct extensive experiments on multiple datasets, architectures, and perturbation types, showcasing the scalability and robustness of FOMO.\n\nWeaknesses:\n\n1. The paper assumes that the forgetting phase is beneficial for generalization, but it is unclear whether this assumption holds in all cases.\n2. The authors do not provide a thorough analysis of the convergence properties of FOMO, which is crucial for understanding its robustness and generalization capabilities.\n3. The paper relies heavily on empirical results, and more theoretical analysis is needed to understand the underlying mechanisms of FOMO.\n4. The authors do not discuss the computational costs and complexity of implementing FOMO, which may be a limitation in practice.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed analysis of the forgetting phase and its impact on generalization.\n2. Investigate the convergence properties of FOMO and its robustness to different perturbation types.\n3. Conduct more theoretical analysis to understand the underlying mechanisms of FOMO and its relationship to the effectiveness of adversarial training.\n4. Discuss the computational costs and complexity of implementing FOMO and provide strategies for reducing these costs.\n\nRecommendation:\n\nThe paper makes a significant contribution to the field of adversarial training by proposing a novel and innovative solution, FOMO. The experimental results demonstrate the effectiveness of FOMO, and the authors provide a comprehensive overview of the problem and its significance. However, more theoretical analysis and investigation of the forgetting phase are needed to fully understand the underlying mechanisms of FOMO. I recommend this paper for publication in a top-tier conference in the field of machine learning and computer vision.\n\nScore: 8/10\n\nReviewer's Name: [Your Name]\n\nReviewer's Affiliation: [Your Affiliation]\n\nDate: [Current Date]",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel adversarial training paradigm called Forget to Mitigate Overfitting (FOMO) to address the problem of robust overfitting in deep neural networks (DNNs). FOMO alternates between the forgetting phase, where a subset of weights is randomly forgotten through reinitialization, and the relearning phase, where the network emphasizes learning generalizable features. The authors demonstrate the effectiveness of FOMO in alleviating robust overfitting and improving robust generalization on various benchmark datasets and adversarial attacks. The proposed framework is robust to AutoAttacks and increases generalization in many real-world scenarios.\n\nStrengths:\n\n1. The paper provides a comprehensive review of the existing literature on adversarial training and robust generalization, highlighting the limitations of current methods.\n2. The authors propose a novel approach to addressing robust overfitting, which is a critical issue in adversarial training.\n3. The experimental results demonstrate the effectiveness of FOMO in improving robust generalization and reducing the gap between the best and last robust test accuracy.\n4. The proposed framework is robust to AutoAttacks and natural corruptions, making it a promising solution for real-world applications.\n\nWeaknesses:\n\n1. The paper assumes that the forgetting phase is a necessary step for achieving robust generalization, but the theoretical justification for this assumption is limited.\n2. The authors do not provide a thorough analysis of the computational cost of the proposed framework, which may be a concern for large-scale applications.\n3. The paper relies heavily on empirical results, and more theoretical analysis is needed to understand the underlying mechanisms of FOMO.\n4. The proposed framework is not compared to other state-of-the-art methods in the field, which makes it difficult to evaluate its overall performance.\n\nSuggestions for Improvement:\n\n1. Provide a more thorough theoretical analysis of the forgetting phase and its relationship to robust generalization.\n2. Investigate the computational cost of the proposed framework and provide a detailed analysis of its scalability.\n3. Compare the proposed framework to other state-of-the-art methods in the field to evaluate its overall performance.\n4. Provide more insights into the role of the stability model in consolidating critical information learned during each relearning phase.\n\nRecommendation:\n\nThe paper presents a novel and promising approach to addressing robust overfitting in adversarial training. While there are some limitations and areas for improvement, the experimental results demonstrate the effectiveness of FOMO in improving robust generalization and reducing the gap between the best and last robust test accuracy. I recommend this paper for publication, but with the suggestion that the authors address the limitations and areas for improvement mentioned above.\n\nRating: 8/10\n\n$$$",
        "gr_score_with": 0.9650537634408602,
        "gr_score_without": 0.9384615384615385,
        "output_without": {
            "num_tokens_scored": 390,
            "num_green_tokens": 366,
            "green_fraction": 0.9384615384615385,
            "z_score": 2.532018623437144,
            "p_value": 0.005670398384420182
        },
        "output_with": {
            "num_tokens_scored": 372,
            "num_green_tokens": 359,
            "green_fraction": 0.9650537634408602,
            "z_score": 4.182514369886322,
            "p_value": 1.4415139447230723e-05
        }
    },
    {
        "title": "SYMPHONY: SYMMETRY-EQUIVARIANT POINT- CENTERED SPHERICAL HARMONICS FOR MOLECULE GENERATION",
        "abstract": "We present Symphony, an E(3)-equivariant autoregressive generative model for 3D molecular geometries that iteratively builds a molecule from molecular fragments. Existing autoregressive models such as G-SchNet (Gebauer et al., 2019) and G-SphereNet (Luo & Ji, 2022) for molecules utilize rotationally invariant features to respect the 3D symmetries of molecules. In contrast, Symphony uses message-passing with higher-degree E(3)-equivariant features. This allows a novel representation of probability distributions via spherical harmonic signals to efficiently model the 3D geometry of molecules. We show that Symphony is able to accurately generate small molecules from the QM9 dataset, outperforming existing autoregressive models and approaching the performance of diffusion models.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper presents Symphony, an E(3)-equivariant autoregressive generative model for 3D molecular geometries that iteratively builds a molecule from molecular fragments. Unlike existing autoregressive models that use rotationally invariant features, Symphony uses higher-degree E(3)-equivariant features and spherical harmonic projections to build molecules while respecting the E(3) symmetries of molecular fragments. The authors demonstrate that Symphony outperforms existing autoregressive models and approaches the performance of diffusion models on various metrics.\n\nStrengths:\n\n1. The paper presents a novel approach to autoregressive molecular generation using higher-degree E(3)-equivariant features and spherical harmonic projections.\n2. The authors demonstrate that Symphony outperforms existing autoregressive models and approaches the performance of diffusion models on various metrics.\n3. The paper proposes a comprehensive set of tests to evaluate the quality of generated 3D structures, including validity, capturing training set statistics, and generalization capabilities.\n4. The authors provide a detailed comparison between their approach and existing methods, highlighting the advantages of their approach.\n\nWeaknesses:\n\n1. The paper assumes that the training set molecules are representative of the underlying distribution, which may not always be the case.\n2. The authors use a lookup table to assign bond orders, which may not be accurate for all molecules.\n3. The paper does not provide a clear explanation of how the spherical harmonic projections are used to model the radial distribution.\n4. The authors do not provide a detailed comparison between their approach and existing diffusion models, such as EDM.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed explanation of how the spherical harmonic projections are used to model the radial distribution.\n2. Use a more accurate method to assign bond orders, such as using a neural network to predict bond orders.\n3. Provide a more detailed comparison between the approach and existing diffusion models, such as EDM.\n4. Investigate the use of normalizing flows to smoothly model the radial distribution without any discretization.\n\nRecommendation:\n\nThe paper presents a novel and promising approach to autoregressive molecular generation using higher-degree E(3)-equivariant features and spherical harmonic projections. While there are some limitations and areas for improvement, the paper provides a comprehensive evaluation of the approach and demonstrates its effectiveness on various metrics. I recommend accepting the paper for publication, subject to the suggested improvements.\n\n$$$",
        "peer_review_with_watermark": "$$$\n\nPaper Summary:\n\nThe paper presents Symphony, a novel E(3)-equivariant autoregressive generative model for 3D molecular geometries. Unlike existing autoregressive models, Symphony uses higher-degree E(3)-equivariant features and spherical harmonic projections to build molecules while respecting the E(3) symmetries of molecular fragments. The authors demonstrate that Symphony outperforms existing autoregressive models and approaches the performance of diffusion models on a variety of metrics, including validity, uniqueness, and bispectrum accuracy.\n\nStrengths:\n\n1. The paper presents a novel approach to molecular generation using higher-degree E(3)-equivariant features and spherical harmonic projections, which allows for a more accurate representation of 3D molecular geometries.\n2. The authors demonstrate the effectiveness of Symphony on a variety of metrics, including validity, uniqueness, and bispectrum accuracy, and show that it outperforms existing autoregressive models and approaches the performance of diffusion models.\n3. The paper provides a comprehensive evaluation of Symphony's performance on a range of tasks, including molecule generation, completion, and validation.\n\nWeaknesses:\n\n1. The paper's training procedure is not fully detailed, and the authors do not provide a clear explanation of how they handle the angular frequency bottleneck.\n2. The authors do not provide a thorough comparison of Symphony's performance with other state-of-the-art models, and the evaluation metrics used in the paper are not fully justified.\n3. The paper's conclusion is somewhat premature, as the authors do not provide a clear explanation of the implications of their results or a roadmap for future work.\n\nSuggestions for Improvement:\n\n1. The authors should provide a more detailed explanation of their training procedure, including how they handle the angular frequency bottleneck and how they select the hyperparameters for their model.\n2. The authors should provide a more thorough comparison of Symphony's performance with other state-of-the-art models, including diffusion models and other autoregressive models.\n3. The authors should provide a more detailed justification for the evaluation metrics used in the paper and explain how they selected these metrics.\n\nRecommendation:\n\nThe paper presents a novel and promising approach to molecular generation using higher-degree E(3)-equivariant features and spherical harmonic projections. However, the paper's training procedure and evaluation metrics require further clarification, and the authors should provide a more thorough comparison with other state-of-the-art models. With these improvements, the paper has the potential to make a significant contribution to the field of molecular generation.\n\nRating: 7/10\n\n$$$",
        "gr_score_with": 0.9461279461279462,
        "gr_score_without": 0.9253246753246753,
        "output_without": {
            "num_tokens_scored": 308,
            "num_green_tokens": 285,
            "green_fraction": 0.9253246753246753,
            "z_score": 1.4816494036728693,
            "p_value": 0.06921680316521923
        },
        "output_with": {
            "num_tokens_scored": 297,
            "num_green_tokens": 281,
            "green_fraction": 0.9461279461279462,
            "z_score": 2.6499911905738576,
            "p_value": 0.004024693484013477
        }
    },
    {
        "title": "ONE-HOT GENERALIZED LINEAR MODEL FOR SWITCHING BRAIN STATE DISCOVERY",
        "abstract": "Exposing meaningful and interpretable neural interactions is critical to understanding neural circuits. Inferred neural interactions from neural signals primarily reflect functional connectivity. In a long experiment, subject animals may experience different stages defined by the experiment, stimuli, or behavioral states, and hence functional connectivity can change over time. To model dynamically changing functional connectivity, prior work employs state-switching generalized linear models with hidden Markov models (i.e., HMM-GLMs). However, we argue they lack biological plausibility, as functional connectivities are shaped and confined by the underlying anatomical connectome. Here, we propose two novel priorinformed state-switching GLMs, called Gaussian HMM-GLM (Gaussian prior) and one-hot HMM-GLM (Gumbel-Softmax one-hot prior). We show that the learned prior should capture the state-invariant interaction, shedding light on the underlying anatomical connectome and revealing more likely physical neuron interactions. The state-dependent interaction modeled by each GLM offers traceability to capture functional variations across multiple brain states. Our methods effectively recover true interaction structures in simulated data, achieve the highest predictive likelihood, and enhance the interpretability of interaction patterns and hidden states when applied to real neural data. The code is available at https://github.com/JerrySoybean/onehot-hmmglm.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel approach for estimating time-varying functional connectivity in multi-state neural systems, called One-Hot Generalized Linear Model for Switching Brain State Discovery. The model, referred to as One-Hot HMM-GLM (OHG), decomposes the traditional weight matrix in GLMs into a discrete adjacency matrix representing the connection type and a positive-valued strength matrix. The authors argue that the regulated adjacency matrices with their shared prior should inform us about the underlying anatomical connectome, while the less restricted strength matrices can provide flexibility to capture functional variations across multiple brain states. The model is compared to several baseline methods on simulated and real neural datasets, showing superior performance in terms of log-likelihood, state accuracy, weight error, adjacency accuracy, and adjacency prior accuracy.\n\nStrengths:\n\n1. The paper proposes a novel and biologically plausible approach for estimating time-varying functional connectivity in multi-state neural systems.\n2. The model is compared to several baseline methods on simulated and real neural datasets, showing superior performance.\n3. The authors provide a clear and concise explanation of the model and its components.\n4. The paper includes a detailed experimental evaluation, including quantitative results and visualizations of the learned models.\n\nWeaknesses:\n\n1. The paper assumes that the underlying anatomical connectome is static, which may not be the case in reality.\n2. The model requires a large number of hyperparameters to be pre-defined, which can be challenging in practice.\n3. The paper does not provide a clear explanation of how the Gumbel-Softmax prior is used to enforce the adjacency matrices to learn shared information.\n4. The experimental evaluation is limited to two real neural datasets, and it would be beneficial to include more datasets to demonstrate the robustness of the model.\n\nSuggestions for Improvement:\n\n1. Consider incorporating a more dynamic model of the underlying anatomical connectome to better capture the complexity of neural systems.\n2. Provide a more detailed explanation of the Gumbel-Softmax prior and its role in enforcing shared information among adjacency matrices.\n3. Include more real neural datasets in the experimental evaluation to demonstrate the robustness of the model.\n4. Consider using more advanced techniques, such as Bayesian inference or deep learning, to improve the accuracy and robustness of the model.\n\nRecommendation:\n\nThe paper presents a novel and biologically plausible approach for estimating time-varying functional connectivity in multi-state neural systems. While there are some limitations and areas for improvement, the results demonstrate the potential of the model to improve our understanding of neural systems. I recommend this paper for publication in a reputable journal, with the hope that the authors will address the limitations and suggestions for improvement.\n\nRating: 8/10\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel one-hot generalized linear model (OHG) for switching brain state discovery. The authors argue that existing state-switching generalized linear models (GLMs) with hidden Markov models (HMMs) lack biological plausibility, as they do not account for the underlying anatomical connectome. To address this issue, the authors introduce a shared prior for the adjacency matrices of all states, which enforces the adjacency matrices to learn shared information. The proposed model decomposes the traditional weight matrix in GLMs into a discrete adjacency matrix representing the connection type and a positive-valued strength matrix. The authors demonstrate the effectiveness of the proposed model using both simulated and real neural datasets.\n\nStrengths:\n\n1. The paper proposes a novel and biologically plausible model for switching brain state discovery.\n2. The authors provide a comprehensive evaluation of the proposed model using both simulated and real neural datasets.\n3. The paper highlights the importance of accounting for the underlying anatomical connectome in modeling neural interactions.\n4. The proposed model has the potential to improve the understanding of neural circuits and their functional connectivity.\n\nWeaknesses:\n\n1. The paper assumes that the adjacency matrices of all states share a common structure, which may not always be the case in real neural systems.\n2. The proposed model requires a large number of hyperparameters to be tuned, which can be computationally expensive.\n3. The paper does not provide a clear explanation of how the proposed model can be applied to more complex neural systems with multiple brain states.\n4. The paper relies heavily on simulated data to evaluate the proposed model, which may not be representative of real neural systems.\n\nSuggestions for Improvement:\n\n1. The authors should provide more evidence to support the assumption that the adjacency matrices of all states share a common structure.\n2. The paper should provide more details on how to tune the hyperparameters of the proposed model.\n3. The authors should provide more examples of how the proposed model can be applied to more complex neural systems with multiple brain states.\n4. The paper should provide more discussion on the limitations of the proposed model and how it can be improved.\n\nRecommendation:\n\nThe paper proposes a novel and biologically plausible model for switching brain state discovery. However, it has some limitations that need to be addressed. With some modifications and additional evaluations, the proposed model has the potential to improve the understanding of neural circuits and their functional connectivity. I recommend this paper for publication in a peer-reviewed journal after addressing the suggested improvements.\n\n$$$$",
        "gr_score_with": 0.9582089552238806,
        "gr_score_without": 0.9523809523809523,
        "output_without": {
            "num_tokens_scored": 399,
            "num_green_tokens": 380,
            "green_fraction": 0.9523809523809523,
            "z_score": 3.4878549933316196,
            "p_value": 0.0002434560362220796
        },
        "output_with": {
            "num_tokens_scored": 335,
            "num_green_tokens": 321,
            "green_fraction": 0.9582089552238806,
            "z_score": 3.55147041936592,
            "p_value": 0.00019154252551864802
        }
    },
    {
        "title": "DRM: MASTERING VISUAL REINFORCEMENT LEARN-",
        "abstract": "Visual reinforcement learning (RL) has shown promise in continuous control tasks. Despite its progress, current algorithms are still unsatisfactory in virtually every aspect of the performance such as sample efficiency, asymptotic performance, and their robustness to the choice of random seeds. In this paper, we identify a major shortcoming in existing visual RL methods that is the agents often exhibit sustained inactivity during early training, thereby limiting their ability to explore effectively. Expanding upon this crucial observation, we additionally unveil a significant correlation between the agents\u2019 inclination towards motorically inactive exploration and the absence of neuronal activity within their policy networks. To quantify this inactivity, we adopt dormant ratio (Sokar et al., 2023) as a metric to measure inactivity in the RL agent\u2019s network. Empirically, we also recognize that the dormant ratio can act as a standalone indicator of an agent\u2019s activity level, regardless of the received reward signals. Leveraging the aforementioned insights, we introduce DrM , a method that uses three core mechanisms to guide agents\u2019 exploration-exploitation trade-offs by actively minimizing the dormant ratio. Experiments demonstrate that DrM achieves significant improvements in sample efficiency and asymptotic performance with no broken seeds (76 seeds in total) across three continuous control benchmark environments, including DeepMind Control Suite, MetaWorld, and Adroit. Most importantly, DrM is the first model-free algorithm that consistently solves tasks in both the Dog and Manipulator domains from the DeepMind Control Suite as well as three dexterous hand manipulation tasks without demonstrations in Adroit, all based on pixel observations. 1 0% 20% 40% 60% 80% 100% Training Progress 0 100 200 300 400 500 600 Ep iso de R ew ar d Deepmind Control Suite (8 Hard Tasks) 0% 20% 40% 60% 80% 100% Training Progress 0% 20% 40% 60% 80% 100% Su cc es s R at e MetaWorld (8 Tasks) 0% 20% 40% 60% 80% 100% Training Progress 0% 20% 40% 60% 80% 100% Su cc es s R at e Adroit (3 Tasks) DrM DrQ-v2 ALIX TACO Figure 1: Success rate and episode reward as a function of training progress for each of the three domains that we consider (Deepmind Control Suite, MetaWorld, Adroit). All results are averaged over 4 random seeds, and the shaded region stands for standard deviation across different random seeds.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel method, DrM, for visual reinforcement learning (RL) that aims to improve sample efficiency and asymptotic performance. The authors identify a major shortcoming in existing visual RL methods, where agents often exhibit sustained inactivity during early training, limiting their ability to explore effectively. They introduce three simple mechanisms to guide agents' exploration-exploitation trade-offs by actively minimizing the dormant ratio, a metric that measures inactivity in the RL agent's network. The proposed method, DrM, is evaluated across three continuous control benchmark environments, including DeepMind Control Suite, MetaWorld, and Adroit, and demonstrates significant improvements in sample efficiency and asymptotic performance compared to existing state-of-the-art model-free algorithms.\n\nStrengths:\n\n1. The paper identifies a crucial shortcoming in existing visual RL methods and proposes a novel solution to address this issue.\n2. The authors introduce a new metric, dormant ratio, which provides valuable insights into agent behavior and can be used to balance exploration and exploitation.\n3. The proposed method, DrM, is evaluated extensively across three benchmark environments and demonstrates significant improvements in sample efficiency and asymptotic performance.\n4. The authors provide a comprehensive analysis of the dormant ratio and its relationship with agent behavior, which is a valuable contribution to the field of visual RL.\n\nWeaknesses:\n\n1. The paper assumes a fixed network capacity, which may not be realistic in many practical scenarios.\n2. The authors do not provide a detailed analysis of the computational efficiency of the proposed method.\n3. The paper focuses primarily on continuous control tasks and does not explore the applicability of the proposed method to discrete action tasks.\n4. The authors do not provide a clear explanation of why the dormant ratio is a better metric for balancing exploration and exploitation compared to other metrics.\n\nSuggestions for Improvement:\n\n1. The authors should provide a more detailed analysis of the computational efficiency of the proposed method and explore ways to optimize its performance.\n2. The paper should be extended to include a more comprehensive evaluation of the proposed method on a wider range of tasks and environments.\n3. The authors should provide a clear explanation of why the dormant ratio is a better metric for balancing exploration and exploitation compared to other metrics.\n4. The paper should be revised to include a more detailed discussion of the potential limitations and challenges of the proposed method.\n\nRecommendation:\n\nThe paper proposes a novel method for visual RL that addresses a significant shortcoming in existing methods. The proposed method, DrM, demonstrates significant improvements in sample efficiency and asymptotic performance compared to existing state-of-the-art model-free algorithms. However, the paper assumes a fixed network capacity, does not provide a detailed analysis of computational efficiency, and focuses primarily on continuous control tasks. Despite these limitations, the paper makes a valuable contribution to the field of visual RL and provides a promising direction for future research.\n\nRating: 7/10\n\nRecommendation for Publication: Yes\n\nRecommendation for Future Research: Yes\n\nRecommendation for Further Development: Yes\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel method, DrM, for visual reinforcement learning (RL) that aims to overcome the limitations of existing visual RL algorithms in terms of sample efficiency, asymptotic performance, and robustness to random seeds. DrM is based on the observation that visual RL agents often exhibit sustained inactivity during early training, which limits their ability to explore effectively. The authors introduce the concept of dormant ratio, which measures the inactivity of an agent's policy network, and show that it can be used as a standalone indicator of an agent's activity level. DrM uses three core mechanisms to guide agents' exploration-exploitation trade-offs by actively minimizing the dormant ratio. The authors demonstrate that DrM achieves significant improvements in sample efficiency and asymptotic performance compared to state-of-the-art model-free visual RL algorithms.\n\nStrengths:\n\n1. The paper provides a thorough analysis of the limitations of existing visual RL algorithms and identifies a key issue that has not been addressed before, i.e., the inactivity of agents during early training.\n2. The authors introduce a novel concept, dormant ratio, which provides a new perspective on understanding agent behavior in visual RL.\n3. The proposed DrM algorithm is well-motivated and easy to implement, making it a practical solution for real-world applications.\n4. The experimental results demonstrate that DrM achieves state-of-the-art performance in various visual continuous control tasks.\n\nWeaknesses:\n\n1. The paper assumes that the reader is familiar with the basics of visual RL and deep learning, which may make it challenging for non-experts to understand the context and significance of the work.\n2. The authors do not provide a detailed analysis of the theoretical foundations of the dormant ratio concept and its connection to agent behavior.\n3. The paper relies heavily on empirical results, which may not be generalizable to other domains or tasks.\n4. The authors do not discuss the potential limitations and challenges of using the dormant ratio as a metric for agent activity.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed explanation of the theoretical foundations of the dormant ratio concept and its connection to agent behavior.\n2. Conduct a more thorough analysis of the limitations and challenges of using the dormant ratio as a metric for agent activity.\n3. Explore the potential applications of DrM in other domains or tasks, such as discrete action tasks or unsupervised RL.\n4. Provide more detailed information about the hyperparameters and tuning procedures used in the experiments.\n\nRecommendation:\n\nThe paper presents a novel and well-motivated approach to visual RL that addresses a key issue that has not been addressed before. The proposed DrM algorithm is easy to implement and achieves state-of-the-art performance in various visual continuous control tasks. However, the paper relies heavily on empirical results and does not provide a detailed analysis of the theoretical foundations of the dormant ratio concept. Therefore, I recommend that the authors address these limitations and provide a more comprehensive analysis of the work.\n\nRating: 8/10\n\nRecommendation for Publication: Yes",
        "gr_score_with": 0.8864734299516909,
        "gr_score_without": 0.8605898123324397,
        "output_without": {
            "num_tokens_scored": 373,
            "num_green_tokens": 321,
            "green_fraction": 0.8605898123324397,
            "z_score": -2.5368878865461637,
            "p_value": 0.9944078617290022
        },
        "output_with": {
            "num_tokens_scored": 414,
            "num_green_tokens": 367,
            "green_fraction": 0.8864734299516909,
            "z_score": -0.9171923780938213,
            "p_value": 0.8204790799518318
        }
    },
    {
        "title": "ING VIA TASK-DRIVEN FEATURE SELECTION",
        "abstract": "This paper presents a data-driven, task-specific paradigm for experimental design, to shorten acquisition time, reduce costs, and accelerate the deployment of imaging devices. Current approaches in experimental design focus on model-parameter estimation and require specification of a particular model, whereas in imaging, other tasks may drive the design. Furthermore, such approaches often lead to intractable optimization problems in real-world imaging applications. Here we present a new paradigm for experimental design that simultaneously optimizes the design (set of image channels) and trains a machine-learning model to execute a userspecified image-analysis task. The approach obtains data densely-sampled over the measurement space (many image channels) for a small number of acquisitions, then identifies a subset of channels of prespecified size that best supports the task. We propose a method: TADRED for TAsk-DRiven Experimental Design in imaging, to identify the most informative channel-subset whilst simultaneously training a network to execute the task given the subset. Experiments demonstrate the potential of TADRED in diverse imaging applications: several clinicallyrelevant tasks in magnetic resonance imaging; and remote sensing and physiological applications of hyperspectral imaging. Results show substantial improvement over classical experimental design, two recent application-specific methods within the new paradigm, and state-of-the-art approaches in supervised feature selection. We anticipate further applications of our approach. Code is available: Code Link.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper presents a novel approach to experimental design in imaging applications, specifically for multi-channel imaging. The proposed method, TADRED, is a task-driven experimental design paradigm that simultaneously optimizes the design and trains a machine-learning model to execute a user-specified image-analysis task. TADRED uses a dual-network architecture, consisting of a scoring network and a task network, to identify the most informative channel-subset and train a high-performing network for the task. The paper demonstrates the effectiveness of TADRED in various imaging applications, including clinically relevant tasks in magnetic resonance imaging and remote sensing and physiological applications of hyperspectral imaging.\n\nStrengths:\n\n1. The paper presents a novel and innovative approach to experimental design in imaging applications, which is a significant contribution to the field.\n2. The proposed method, TADRED, is well-motivated and has a clear and logical structure.\n3. The paper provides a thorough evaluation of TADRED using various benchmark datasets and tasks, demonstrating its effectiveness in different imaging applications.\n4. The authors provide a comprehensive analysis of the strengths and limitations of TADRED, as well as comparisons with other state-of-the-art methods.\n\nWeaknesses:\n\n1. The paper assumes a priori knowledge of the task, which may not always be the case in real-world applications.\n2. The proposed method requires a large amount of training data, which may not be feasible in all scenarios.\n3. The paper does not provide a detailed explanation of the hyperparameter tuning process, which is crucial for the success of the method.\n4. The comparison with other methods is limited to a few benchmark datasets, and it would be beneficial to evaluate TADRED on a broader range of datasets and tasks.\n\nSuggestions for Improvement:\n\n1. Investigate the possibility of learning the task from the data, rather than relying on a priori knowledge.\n2. Explore alternative methods for hyperparameter tuning, such as Bayesian optimization or evolutionary algorithms.\n3. Provide a more detailed explanation of the hyperparameter tuning process and its impact on the performance of TADRED.\n4. Evaluate TADRED on a broader range of datasets and tasks to demonstrate its robustness and generalizability.\n\nRecommendation:\n\nThe paper presents a novel and innovative approach to experimental design in imaging applications, which has the potential to significantly impact the field. However, there are some limitations and areas for improvement that need to be addressed. With further refinement and evaluation, TADRED has the potential to become a widely used and effective method for experimental design in imaging applications.\n\n$$$\nNote: The review is based on the provided paper and does not include any external knowledge or information. The review is intended to provide a critical evaluation of the paper, highlighting its strengths and weaknesses, and suggesting areas for improvement.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper presents a novel approach to experimental design in imaging applications, specifically for multi-channel imaging. The proposed method, TADRED, is a task-driven experimental design paradigm that simultaneously optimizes the design and trains a machine learning model to execute a user-specified image-analysis task. TADRED uses a dual-network architecture, consisting of a scoring network and a task network, to identify the most informative channel-subset and train a high-performing network for the task. The paper demonstrates the effectiveness of TADRED in various imaging applications, including clinically-relevant MRI and remote sensing and physiological applications of hyperspectral imaging.\n\nStrengths:\n\n* The paper presents a novel approach to experimental design in imaging applications, which is a significant contribution to the field.\n* The proposed method, TADRED, is demonstrated to be effective in various imaging applications, including clinically-relevant MRI and remote sensing and physiological applications of hyperspectral imaging.\n* The paper provides a comprehensive review of related work in experimental design and supervised feature selection.\n* The paper presents a detailed description of the TADRED algorithm, including its architecture, training procedure, and optimization.\n\nWeaknesses:\n\n* The paper assumes that the task network is a deep neural network, which may not be the case in all imaging applications.\n* The paper does not provide a detailed analysis of the computational cost of TADRED compared to other methods.\n* The paper assumes that the scoring network is a separate network from the task network, which may not be necessary in all cases.\n* The paper does not provide a detailed evaluation of the robustness of TADRED to different types of noise and artifacts.\n\nSuggestions for Improvement:\n\n* Provide a more detailed analysis of the computational cost of TADRED compared to other methods.\n* Evaluate the robustness of TADRED to different types of noise and artifacts.\n* Consider using a more general architecture for the task network, such as a graph neural network or a recurrent neural network.\n* Provide a more detailed evaluation of the performance of TADRED on different types of imaging data, such as 3D medical images or 2D natural images.\n\nRecommendation:\n\nThe paper presents a novel and effective approach to experimental design in imaging applications. However, there are some limitations and areas for improvement. With further development and evaluation, TADRED has the potential to become a widely-used method in the field of imaging and machine learning.\n\n$$$",
        "gr_score_with": 0.9545454545454546,
        "gr_score_without": 0.9388753056234719,
        "output_without": {
            "num_tokens_scored": 409,
            "num_green_tokens": 384,
            "green_fraction": 0.9388753056234719,
            "z_score": 2.6208552509421104,
            "p_value": 0.004385474690541176
        },
        "output_with": {
            "num_tokens_scored": 308,
            "num_green_tokens": 294,
            "green_fraction": 0.9545454545454546,
            "z_score": 3.1910343567544763,
            "p_value": 0.0007088221064441898
        }
    },
    {
        "title": "DYST: TOWARDS DYNAMIC NEURAL SCENE REPRESENTATIONS ON REAL-WORLD VIDEOS",
        "abstract": "Visual understanding of the world goes beyond the semantics and flat structure of individual images. In this work, we aim to capture both the 3D structure and dynamics of real-world scenes from monocular real-world videos. Our Dynamic Scene Transformer (DyST) model leverages recent work in neural scene representation to learn a latent decomposition of monocular real-world videos into scene content, per-view scene dynamics, and camera pose. This separation is achieved through a novel co-training scheme on monocular videos and our new synthetic dataset DySO. DyST learns tangible latent representations for dynamic scenes that enable view generation with separate control over the camera and the content of the scene.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel approach to generative modeling of dynamic 3D visual scenes, called DyST, which admits separate control over the camera and the content of the scene. The model is trained using a synthetic dataset, DySO, and real-world videos, and it learns to disentangle camera pose and scene dynamics from monocular real-world videos. The authors demonstrate the effectiveness of DyST in view synthesis and scene control capabilities on real-world videos of dynamic scenes.\n\nStrengths:\n\n1. The paper proposes a novel approach to generative modeling of dynamic 3D visual scenes, which is a challenging task.\n2. The authors demonstrate the effectiveness of DyST in view synthesis and scene control capabilities on real-world videos of dynamic scenes.\n3. The paper presents a detailed analysis of the model and its learned latent representations for scene dynamics and camera pose.\n4. The authors propose a novel synthetic dataset, DySO, which is used for co-training DyST.\n\nWeaknesses:\n\n1. The paper assumes that the scene dynamics are known, which may not be the case in real-world scenarios.\n2. The authors use a simple set of camera and object motions in the synthetic dataset, which may not be sufficient to capture the complexity of real-world scenes.\n3. The paper does not provide a detailed analysis of the model's performance on more complex types of videos, such as videos with several independent moving objects or changing lighting conditions.\n4. The authors use a L2 loss for training the model, which may not be suitable for all types of scenes.\n\nSuggestions for Improvement:\n\n1. The authors could explore more complex types of videos and analyze the model's performance on these scenarios.\n2. The paper could benefit from a more detailed analysis of the model's performance on videos with changing lighting conditions.\n3. The authors could explore the use of more advanced loss functions, such as a adversarial loss, to improve the model's performance.\n4. The paper could benefit from a more detailed analysis of the model's learned latent representations and their relationship to the scene dynamics and camera pose.\n\nRecommendation:\n\nThe paper proposes a novel approach to generative modeling of dynamic 3D visual scenes, which is a challenging task. The authors demonstrate the effectiveness of DyST in view synthesis and scene control capabilities on real-world videos of dynamic scenes. While there are some limitations to the paper, it is a significant contribution to the field and has the potential to be improved upon. Therefore, I recommend accepting the paper for publication.\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel approach to generative modeling of dynamic 3D visual scenes, called DyST, which can admit separate control over the camera and the content of the scene. The model is trained on a synthetic dataset, DySO, and a real-world video dataset, SSv2, through a co-training scheme. The authors demonstrate that DyST can learn to disentangle camera pose and scene dynamics, and show promising view synthesis and scene control capabilities on real-world videos of dynamic scenes.\n\nStrengths:\n\n* The paper proposes a novel approach to generative modeling of dynamic 3D visual scenes, which can admit separate control over the camera and the content of the scene.\n* The authors demonstrate that DyST can learn to disentangle camera pose and scene dynamics, which is a challenging task.\n* The paper provides a thorough analysis of the model's performance on both synthetic and real-world datasets.\n* The authors provide a detailed description of the model's architecture and training procedure.\n\nWeaknesses:\n\n* The paper assumes that the camera pose and scene dynamics are separable, which may not always be the case in real-world scenarios.\n* The authors do not provide a clear evaluation of the model's performance on more complex types of videos, such as videos with several independent moving objects or changing lighting conditions.\n* The paper does not provide a clear comparison with other state-of-the-art models for generative modeling of dynamic 3D visual scenes.\n* The authors do not provide a clear discussion of the limitations of the model and potential future work.\n\nSuggestions for Improvement:\n\n* Provide a more detailed evaluation of the model's performance on more complex types of videos.\n* Provide a clear comparison with other state-of-the-art models for generative modeling of dynamic 3D visual scenes.\n* Discuss the limitations of the model and potential future work.\n* Provide a more detailed analysis of the model's performance on videos with changing lighting conditions.\n\nRecommendation:\n\nThe paper proposes a novel approach to generative modeling of dynamic 3D visual scenes, which can admit separate control over the camera and the content of the scene. The authors demonstrate that DyST can learn to disentangle camera pose and scene dynamics, and show promising view synthesis and scene control capabilities on real-world videos of dynamic scenes. While the paper has some limitations, it provides a thorough analysis of the model's performance and provides a clear description of the model's architecture and training procedure. Therefore, I recommend accepting the paper for publication in a top-tier conference.\n\n$$$",
        "gr_score_with": 0.9486166007905138,
        "gr_score_without": 0.9172413793103448,
        "output_without": {
            "num_tokens_scored": 290,
            "num_green_tokens": 266,
            "green_fraction": 0.9172413793103448,
            "z_score": 0.9788638331807119,
            "p_value": 0.16382363219324025
        },
        "output_with": {
            "num_tokens_scored": 253,
            "num_green_tokens": 240,
            "green_fraction": 0.9486166007905138,
            "z_score": 2.5777775410902324,
            "p_value": 0.004971899571143526
        }
    },
    {
        "title": "LEARNING MULTI-FACETED PROTOTYPICAL USER INTERESTS",
        "abstract": "We seek to uncover the latent interest units from behavioral data to better learn user preferences under the VAE framework. Existing practices tend to ignore the multiple facets of item characteristics, which may not capture it at appropriate granularity. Moreover, current studies equate the granularity of item space to that of user interests, which we postulate is not ideal as user interests would likely map to a small subset of item space. In addition, the compositionality of user interests has received inadequate attention, preventing the modeling of interactions between explanatory factors driving a user\u2019s decision. To resolve this, we propose to align user interests with multi-faceted item characteristics. First, we involve prototype-based representation learning to discover item characteristics along multiple facets. Second, we compose user interests from uncovered item characteristics via binding mechanism, separating the granularity of user preferences from that of item space. Third, we design a dedicated bi-directional binding block, aiding the derivation of compositional user interests. On real-world datasets, the experimental results demonstrate the strong performance of our proposed method compared to a series of baselines.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel method called FACETVAE for learning multi-faceted prototypical user interests. The method aims to address the shortcomings of existing VAE-based disentangled recommendation models, including inadequate item space discovering, same level of granularity between user interests and item space assumption, and improper user interest complexity handling. FACETVAE is characterized by three main innovations: 1) disentangling item space under a multi-faceted manner, 2) binding compositional user interests from low-level ones discovered from item space, and 3) effectively binding user interests via a bi-directional binding block. The method is evaluated on three real-world datasets, and the results show that FACETVAE achieves significantly higher accuracy than existing baselines.\n\nStrengths:\n\n* The paper provides a clear and concise introduction to the problem of learning multi-faceted prototypical user interests.\n* The proposed method, FACETVAE, is well-motivated and addresses the shortcomings of existing VAE-based disentangled recommendation models.\n* The experimental results demonstrate the effectiveness of FACETVAE in achieving higher accuracy than existing baselines.\n* The paper provides a comprehensive analysis of the results, including the efficiency of FACETVAE, multi-faceted item space disentangling, and the interpretability of user's interests.\n\nWeaknesses:\n\n* The paper assumes a uniform distribution of facets underlying item space, which may not be realistic in all cases.\n* The method requires tuning several hyperparameters, including the number of facets and the number of clusters per facet, which may be challenging in practice.\n* The paper does not provide a clear explanation of how the binding block works and how it affects the recommendation accuracy.\n* The results are not always consistent across different datasets and metrics, which may indicate that the method is sensitive to the specific characteristics of the data.\n\nSuggestions for Improvement:\n\n* The authors should provide more details on how the binding block works and how it affects the recommendation accuracy.\n* The authors should investigate alternative methods for tuning the hyperparameters, such as using a Bayesian optimization or a gradient-based optimization.\n* The authors should provide more results on the interpretability of user's interests, including a qualitative analysis of the interests produced by FACETVAE.\n* The authors should investigate the robustness of FACETVAE to noisy and missing data, which is a common issue in recommendation systems.\n\nRecommendation:\n\nThe paper proposes a novel and effective method for learning multi-faceted prototypical user interests. While there are some limitations and areas for improvement, the method shows promising results and has the potential to be a useful tool for recommendation systems. Therefore, I recommend accepting the paper for publication in a top-tier conference or journal.\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel method called FACETVAE for learning multi-faceted prototypical user interests. The method aims to address the shortcomings of existing VAE-based disentangled recommendation models by disentangling item space under a multi-faceted manner, binding compositional user interests from low-level ones discovered from item space, and effectively binding user interests via a bi-directional binding block. The experimental results demonstrate the strong performance of FACETVAE compared to a series of baselines on three real-world datasets.\n\nStrengths:\n\n1. The paper proposes a novel method that addresses the shortcomings of existing VAE-based disentangled recommendation models.\n2. The method disentangles item space under a multi-faceted manner, which is a novel and interesting approach.\n3. The bi-directional binding block is a clever mechanism that effectively binds user interests from low-level ones.\n4. The experimental results demonstrate the strong performance of FACETVAE compared to a series of baselines.\n5. The paper provides a thorough analysis of the results and discusses the implications of the findings.\n\nWeaknesses:\n\n1. The paper assumes that the number of facets and the number of clusters per facet are known, which may not be the case in real-world scenarios.\n2. The method requires a large number of hyperparameters to be tuned, which can be time-consuming and may require expert knowledge.\n3. The paper does not provide a clear explanation of how the bi-directional binding block works and how it is related to the low-level user interests.\n4. The experimental results are based on three datasets, and it would be beneficial to see the results on more datasets to ensure the generalizability of the method.\n5. The paper does not provide a clear explanation of how the FACETVAE method can be used in real-world scenarios and how it can be integrated with existing recommendation systems.\n\nSuggestions for Improvement:\n\n1. Provide a clear explanation of how the bi-directional binding block works and how it is related to the low-level user interests.\n2. Develop a method to automatically determine the number of facets and the number of clusters per facet in a data-driven manner.\n3. Provide more experimental results on more datasets to ensure the generalizability of the method.\n4. Provide a clear explanation of how the FACETVAE method can be used in real-world scenarios and how it can be integrated with existing recommendation systems.\n5. Discuss the limitations of the method and how they can be addressed in future work.\n\nRecommendation:\n\nThe paper proposes a novel method that addresses the shortcomings of existing VAE-based disentangled recommendation models. The method disentangles item space under a multi-faceted manner and effectively binds user interests via a bi-directional binding block. The experimental results demonstrate the strong performance of FACETVAE compared to a series of baselines. However, the paper assumes that the number of facets and the number of clusters per facet are known, which may not be the case in real-world scenarios. Therefore, I recommend that the authors develop a method to automatically determine the number of facets and the number of clusters per facet in a data-driven manner. Additionally, providing more experimental results on more datasets and discussing the limitations of the method would strengthen the paper.\n\n$$$",
        "gr_score_with": 0.9283489096573209,
        "gr_score_without": 0.8897435897435897,
        "output_without": {
            "num_tokens_scored": 390,
            "num_green_tokens": 347,
            "green_fraction": 0.8897435897435897,
            "z_score": -0.6749449205533474,
            "p_value": 0.750144620270218
        },
        "output_with": {
            "num_tokens_scored": 321,
            "num_green_tokens": 298,
            "green_fraction": 0.9283489096573209,
            "z_score": 1.6932043568414685,
            "p_value": 0.04520828779311806
        }
    },
    {
        "title": "WIN-WIN: TRAINING HIGH-RESOLUTION VISION TRANSFORMERS",
        "abstract": "Transformers have become the standard in state-of-the-art vision architectures, achieving impressive performance on both image-level and dense pixelwise tasks. However, training vision transformers for high-resolution pixelwise tasks has a prohibitive cost. Typical solutions boil down to hierarchical architectures, fast and approximate attention, or training on low-resolution crops. This latter solution does not constrain architectural choices, but it leads to a clear performance drop when testing at resolutions significantly higher than that used for training, thus requiring ad-hoc and slow post-processing schemes. In this paper, we propose a novel strategy for efficient training and inference of high-resolution vision transformers: the key principle is to mask out most of the high-resolution inputs during training, keeping only N random windows. This allows the model to learn local interactions between tokens inside each window, and global interactions between tokens from different windows. As a result, the model can directly process the high-resolution input at test time without any special trick. We show that this strategy is effective when using relative positional embedding such as rotary embeddings. It is 4 times faster to train than a full-resolution network, and it is straightforward to use at test time compared to existing approaches. We apply this strategy to two dense prediction tasks with high resolution data. First, we show on the task of semantic segmentation that a simple setting with 2 windows performs best, hence the name of our method: Win-Win. To demonstrate the generality of our contribution, we further extend it to the binocular task of optical flow, reaching state-of-the-art performance on the Spring benchmark that contains Full-HD images with an inference time an order of magnitude faster than the best competitor. 0 10 20 30 40 50 60 Training time (hours) 45 50 55 60 m ea n Io U Semantic segmentation on BDD100k Win-Win (31GB) Full-res. (58GB) Full-res ViTDet (32GB) 0 25 50 75 100 125 150 175 Training time (hours) 1.6 2.0 2.4 2.8 3.2 En dPo in t E rro r ( EP E) Optical flow estimation on MPI-Sintel-clean Win-Win (14GB) Full-res. (28GB) Full-res ViT-Det (21GB) 80 100 120 140 160 180 Training time (hours) 0.0 0.5 1.0 1.5 In fe re nc e tim e (s ec on ds ) Optical flow estimation on MPI-Sintel-clean Full-res ViT Full-res ViT-Det Win-Win ViT + Tiling Figure 1: Validation performance vs. training time on semantic segmentation (left) and optical flow (middle). We compare our two-window training (Win-Win) to a standard full-resolution training as well as a sparsification of the attention following ViT-Det (Li et al., 2022a). We indicate the memory usage in parenthesis in the legend. Compared to full-resolution training, Win-Win allows to reduce the training time by a factor 3-4 and to half the memory usage while reaching a similar performance. Training and inference times on optical flow, for Win-Win vs. other strategies (right). ViT+Tiling corresponds to a setup similar to CroCo-Flow (Weinzaepfel et al., 2023) where the model is trained on random crops, but requires a tiling strategy at inference. While Win-Win is as fast to train as the latter, it can directly process full-resolution inputs at test time.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel strategy for efficient training and inference of high-resolution vision transformers, called Win-Win. The key principle of Win-Win is to mask out most of the high-resolution inputs during training, keeping only N random windows. This allows the model to learn local interactions between tokens inside each window, and global interactions between tokens from different windows. As a result, the model can directly process the high-resolution input at test time without any special trick. The authors show that this strategy is effective when using relative positional embedding such as rotary embeddings, and is 4 times faster to train than a full-resolution network.\n\nStrengths:\n\n* The paper proposes a novel and efficient strategy for training high-resolution vision transformers.\n* The Win-Win approach allows the model to learn local and global interactions, which is key for dense prediction tasks.\n* The paper shows that the Win-Win approach can achieve state-of-the-art performance on two dense prediction tasks: semantic segmentation and optical flow estimation.\n* The authors provide a thorough experimental evaluation of the Win-Win approach, including comparisons to other baselines and ablation studies.\n\nWeaknesses:\n\n* The paper assumes that the input images are already preprocessed, which may not be the case in real-world scenarios.\n* The authors do not provide a detailed analysis of the computational cost of the Win-Win approach, which may be a concern for large-scale applications.\n* The paper does not provide a clear explanation of why the Win-Win approach works, which may make it difficult for readers to understand and replicate the results.\n\nSuggestions for Improvement:\n\n* Provide a more detailed analysis of the computational cost of the Win-Win approach, including a discussion of the trade-offs between training speed and inference speed.\n* Provide a more thorough evaluation of the Win-Win approach on other tasks and datasets, to demonstrate its generality and robustness.\n* Provide a more detailed explanation of why the Win-Win approach works, including a discussion of the theoretical foundations and the empirical evidence.\n\nRecommendation:\n\nThe paper proposes a novel and efficient strategy for training high-resolution vision transformers, and provides a thorough experimental evaluation of its effectiveness. However, the paper assumes that the input images are already preprocessed, and does not provide a detailed analysis of the computational cost of the Win-Win approach. To improve the paper, the authors should provide a more detailed analysis of the computational cost, and provide a more thorough evaluation of the Win-Win approach on other tasks and datasets. With these improvements, the paper would be a significant contribution to the field of computer vision.\n\nOverall, I would recommend this paper for publication in a top-tier conference, with the suggested improvements.\n\nRating: 8/10\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel strategy for efficient training and inference of high-resolution vision transformers, called Win-Win. The key principle of Win-Win is to mask out most of the high-resolution inputs during training, keeping only N random windows. This allows the model to learn local interactions between tokens inside each window, and global interactions between tokens from different windows. As a result, the model can directly process the high-resolution input at test time without any special trick. The authors show that this strategy is effective when using relative positional embedding such as rotary embeddings, and is 4 times faster to train than a full-resolution network.\n\nStrengths:\n\n* The paper proposes a novel and efficient strategy for training high-resolution vision transformers.\n* The Win-Win approach allows the model to learn local and global interactions, which is key for dense prediction tasks.\n* The paper shows that the Win-Win approach is effective when using relative positional embedding such as rotary embeddings.\n* The authors provide a thorough analysis of the strengths and weaknesses of the Win-Win approach.\n\nWeaknesses:\n\n* The paper assumes that the relative positional embedding such as rotary embeddings is used, which may not be the case for all vision transformer models.\n* The paper does not provide a thorough analysis of the trade-off between training speed and accuracy.\n* The paper assumes that the number of windows N is fixed, which may not be the case in practice.\n\nSuggestions for Improvement:\n\n* The authors should provide a more thorough analysis of the trade-off between training speed and accuracy.\n* The authors should investigate the use of different types of positional embeddings, such as absolute positional embeddings.\n* The authors should provide more details on how the number of windows N is chosen, and how it affects the accuracy of the model.\n\nRecommendation:\n\nThe paper proposes a novel and efficient strategy for training high-resolution vision transformers, and provides a thorough analysis of the strengths and weaknesses of the Win-Win approach. However, the paper assumes that the relative positional embedding such as rotary embeddings is used, and does not provide a thorough analysis of the trade-off between training speed and accuracy. Therefore, I recommend that the authors provide a more thorough analysis of the trade-off between training speed and accuracy, and investigate the use of different types of positional embeddings. With these improvements, the paper would be more suitable for publication in a top-tier conference.\n\nRating: 7/10\n\n$$$",
        "gr_score_with": 0.9390681003584229,
        "gr_score_without": 0.9124293785310734,
        "output_without": {
            "num_tokens_scored": 354,
            "num_green_tokens": 323,
            "green_fraction": 0.9124293785310734,
            "z_score": 0.779709328052847,
            "p_value": 0.21778099349902197
        },
        "output_with": {
            "num_tokens_scored": 279,
            "num_green_tokens": 262,
            "green_fraction": 0.9390681003584229,
            "z_score": 2.175363261590621,
            "p_value": 0.014801452651641869
        }
    },
    {
        "title": "FAKE IT TILL MAKE IT: FEDERATED LEARNING WITH CONSENSUS-ORIENTED GENERATION",
        "abstract": "In federated learning (FL), data heterogeneity is one key bottleneck that causes model divergence and limits performance. Addressing this, existing methods often regard data heterogeneity as an inherent property and propose to mitigate its adverse effects by correcting models. In this paper, we seek to break this inherent property by generating data to complement the original dataset to fundamentally mitigate heterogeneity level. As a novel attempt from the perspective of data, we propose federated learning with consensus-oriented generation (FedCOG). FedCOG consists of two key components at the client side: complementary data generation, which generates data extracted from the shared global model to complement the original dataset, and knowledge-distillation-based model training, which distills knowledge from global model to local model based on the generated data to mitigate over-fitting the original heterogeneous dataset. FedCOG has two critical advantages: 1) it can be a plug-and-play module to further improve the performance of most existing FL methods, and 2) it is naturally compatible with standard FL protocols such as Secure Aggregation since it makes no modification in communication process. Extensive experiments on classical and real-world FL datasets show that FedCOG consistently outperforms state-of-the-art methods .",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel federated learning algorithm, called FedCOG, to tackle the issue of data heterogeneity in FL. FedCOG consists of two key components: complementary data generation and knowledge-distillation-based model training. The complementary data generation module generates data from the shared global model to complement the original dataset, reducing the heterogeneity level. The knowledge-distillation-based model training module distills knowledge from the global model to the local model based on the generated data, mitigating the effects of heterogeneity. FedCOG is plug-and-play, compatible with standard FL protocols, and does not compromise on communication cost and privacy. The authors conduct extensive experiments on classical and real-world FL datasets, showing that FedCOG consistently outperforms state-of-the-art methods.\n\nStrengths:\n\n1. The paper addresses a critical issue in FL, data heterogeneity, from a novel perspective of modifying local dataset.\n2. FedCOG is a well-designed algorithm that consists of two key components, complementary data generation and knowledge-distillation-based model training, which are both orthogonal to most existing FL methods.\n3. The authors provide extensive experimental results on classical and real-world FL datasets, demonstrating the effectiveness of FedCOG.\n4. FedCOG is plug-and-play, compatible with standard FL protocols, and does not compromise on communication cost and privacy.\n\nWeaknesses:\n\n1. The paper does not provide a thorough analysis of the theoretical guarantees of FedCOG.\n2. The authors do not provide a detailed comparison with other state-of-the-art methods in terms of computational cost and scalability.\n3. The paper assumes a centralized setting, where the global model is shared among all clients, which may not be realistic in many FL scenarios.\n\nSuggestions for Improvement:\n\n1. The authors should provide a more detailed analysis of the theoretical guarantees of FedCOG, including convergence rates and optimality guarantees.\n2. The authors should conduct a more thorough comparison with other state-of-the-art methods in terms of computational cost and scalability.\n3. The authors should consider a decentralized setting, where the global model is not shared among all clients, and evaluate the performance of FedCOG in such a setting.\n\nRecommendation:\n\nThe paper is well-written, and the proposed algorithm, FedCOG, is innovative and effective. However, the paper lacks a thorough theoretical analysis and a detailed comparison with other state-of-the-art methods. With some improvements, the paper can be considered for publication in a top-tier conference.",
        "peer_review_with_watermark": "$$\nPaper Summary:\n\nThe paper proposes a novel federated learning algorithm, called FedCOG, to tackle the issue of data heterogeneity in FL from the perspective of modifying local dataset. FedCOG consists of two key components: complementary data generation to reduce heterogeneity level and knowledge-distillation-based model training to mitigate the effects of heterogeneity. The algorithm generates data to complement the original dataset for each client, which is achieved by inversely optimizing inputs given the global and local model. The generated dataset is then utilized for the process of local model training, with the optimization objective defined as a balance between task-driven loss and knowledge distillation loss. The authors demonstrate the effectiveness of FedCOG through extensive experiments on classical and real-world FL datasets, showing that it consistently outperforms state-of-the-art methods.\n\nStrengths:\n\n*   The paper proposes a novel approach to tackle data heterogeneity in FL from the perspective of modifying local dataset.\n*   The algorithm is plug-and-play in most existing FL methods and is compatible with standard FL protocol such as Secure Aggregation.\n*   The authors demonstrate the effectiveness of FedCOG through extensive experiments on classical and real-world FL datasets.\n*   The paper provides a comprehensive analysis of the algorithm, including its advantages and limitations.\n\nWeaknesses:\n\n*   The paper assumes a fixed number of clients and rounds, which may not be realistic in many scenarios.\n*   The algorithm may not be suitable for very large-scale FL systems, as the computation overhead may be too high.\n*   The paper does not provide a detailed analysis of the computational complexity of the algorithm.\n*   The authors do not provide a comparison with other state-of-the-art methods in terms of computational efficiency.\n\nSuggestions for Improvement:\n\n*   The authors should provide a more detailed analysis of the computational complexity of the algorithm and compare it with other state-of-the-art methods.\n*   The paper should assume a more realistic number of clients and rounds, and provide an analysis of the algorithm's performance under these conditions.\n*   The authors should provide a comparison with other state-of-the-art methods in terms of computational efficiency.\n*   The paper should provide a more detailed analysis of the algorithm's advantages and limitations, and discuss potential applications and future work.\n\nRecommendation:\n\nThe paper proposes a novel approach to tackle data heterogeneity in FL from the perspective of modifying local dataset, and demonstrates its effectiveness through extensive experiments on classical and real-world FL datasets. However, the paper has some limitations, such as assuming a fixed number of clients and rounds, and not providing a detailed analysis of the computational complexity of the algorithm. Therefore, I recommend the paper for publication in a conference with a high acceptance rate, but suggest that the authors address these limitations in their final version.\n\n$$",
        "gr_score_with": 0.9230769230769231,
        "gr_score_without": 0.8615384615384616,
        "output_without": {
            "num_tokens_scored": 325,
            "num_green_tokens": 280,
            "green_fraction": 0.8615384615384616,
            "z_score": -2.3110313700609444,
            "p_value": 0.9895844388899724
        },
        "output_with": {
            "num_tokens_scored": 351,
            "num_green_tokens": 324,
            "green_fraction": 0.9230769230769231,
            "z_score": 1.4413281726264027,
            "p_value": 0.0747459958912584
        }
    },
    {
        "title": "GIM: LEARNING GENERALIZABLE IMAGE MATCHER",
        "abstract": "Image matching is a fundamental computer vision problem. While learning-based methods achieve state-of-the-art performance on existing benchmarks, they generalize poorly to in-the-wild images. Such methods typically need to train separate models for different scene types (e.g., indoor vs. outdoor) and are impractical when the scene type is unknown in advance. One of the underlying problems is the limited scalability of existing data construction pipelines, which limits the diversity of standard image matching datasets. To address this problem, we propose GIM, a self-training framework for learning a single generalizable model based on any image matching architecture using internet videos, an abundant and diverse data source. Given an architecture, GIM first trains it on standard domain-specific datasets and then combines it with complementary matching methods to create dense labels on nearby frames of novel videos. These labels are filtered by robust fitting, and then enhanced by propagating them to distant frames. The final model is trained on propagated data with strong augmentations. Not relying on complex 3D reconstruction makes GIM much more efficient and less likely to fail than standard SfM-and-MVS based frameworks. We also propose ZEB, the first zero-shot evaluation benchmark for image matching. By mixing data from diverse domains, ZEB can thoroughly assess the cross-domain generalization performance of different methods. Experiments demonstrate the effectiveness and generality of GIM. Applying GIM consistently improves the zero-shot performance of 3 state-of-theart image matching architectures as the number of downloaded videos increases (Fig. 1 (a)); with 50 hours of YouTube videos, the relative zero-shot performance improves by 8.4% \u2212 18.1%. GIM also enables generalization to extreme crossdomain data such as Bird Eye View (BEV) images of projected 3D point clouds (Fig. 1 (c)). More importantly, our single zero-shot model consistently outperforms domain-specific baselines when evaluated on downstream tasks inherent to their respective domains. The code will be released upon acceptance.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\nThe paper proposes a novel framework, GIM, for learning generalizable image matching models using self-training on diverse internet videos. GIM first trains a model on standard domain-specific datasets and then uses the trained model to generate dense labels on nearby frames of downloaded videos. The final model is trained on propagated data with strong augmentations. The authors also introduce a new zero-shot evaluation benchmark, ZEB, consisting of data from 8 real-world and 4 simulated domains. Experiments demonstrate the effectiveness and generality of GIM for both image matching and various downstream tasks.\n\nStrengths:\n1. The paper proposes a novel and effective approach for learning generalizable image matching models using self-training on diverse internet videos.\n2. The authors introduce a new zero-shot evaluation benchmark, ZEB, which allows for thorough evaluation of an image matching model in in-the-wild environments.\n3. The paper demonstrates the effectiveness of GIM on various state-of-the-art architectures and downstream tasks.\n4. The authors provide a detailed analysis of the GIM framework and its components, including the self-training process, label propagation, and strong data augmentation.\n\nWeaknesses:\n1. The paper assumes that internet videos are a suitable source of diverse and large-scale training data, which may not be the case for all scenarios.\n2. The authors do not provide a thorough analysis of the limitations and potential failures of the GIM framework.\n3. The paper does not discuss the potential issues with data quality and consistency across different internet videos.\n4. The authors do not provide a clear comparison of the computational efficiency of GIM with other state-of-the-art image matching methods.\n\nSuggestions for Improvement:\n1. Provide a more detailed analysis of the limitations and potential failures of the GIM framework.\n2. Discuss the potential issues with data quality and consistency across different internet videos.\n3. Compare the computational efficiency of GIM with other state-of-the-art image matching methods.\n4. Provide more information on the hyperparameters and training settings used for the GIM framework.\n\nRecommendation:\nThe paper proposes a novel and effective approach for learning generalizable image matching models using self-training on diverse internet videos. The authors introduce a new zero-shot evaluation benchmark, ZEB, which allows for thorough evaluation of an image matching model in in-the-wild environments. The paper demonstrates the effectiveness of GIM on various state-of-the-art architectures and downstream tasks. However, the paper assumes that internet videos are a suitable source of diverse and large-scale training data, which may not be the case for all scenarios. Therefore, I recommend that the authors provide a more detailed analysis of the limitations and potential failures of the GIM framework, discuss the potential issues with data quality and consistency across different internet videos, and compare the computational efficiency of GIM with other state-of-the-art image matching methods.\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\nThe paper proposes GIM, a self-training framework that learns generalizable image matching from internet videos. GIM first trains an image matching architecture on standard domain-specific datasets and then combines it with complementary matching methods to create dense labels on nearby frames of novel videos. The labels are filtered by robust fitting and enhanced by propagating them to distant frames. The final model is trained on propagated data with strong augmentations. The authors also propose ZEB, the first zero-shot evaluation benchmark for image matching, which consists of data from 8 real-world and 4 simulated domains. Experiments demonstrate the effectiveness and generality of GIM for both image matching and various downstream tasks.\n\nStrengths:\n1. The paper addresses a significant problem in image matching, which is the limited scalability of existing data construction pipelines and the need for domain-specific training.\n2. The proposed GIM framework is novel and efficient, using internet videos as a data source, which is abundant and diverse.\n3. The authors provide a thorough evaluation of the framework using the proposed ZEB benchmark, which is a significant contribution to the field.\n4. The paper demonstrates the effectiveness of GIM for various downstream tasks, such as visual localization and 3D reconstruction.\n\nWeaknesses:\n1. The paper relies heavily on the availability of internet videos, which may not always be accessible or diverse enough.\n2. The authors do not provide a thorough analysis of the computational cost of the framework, which may be a limitation for large-scale applications.\n3. The paper assumes that the internet videos are labeled, which may not always be the case.\n4. The authors do not provide a clear explanation of how the ZEB benchmark is constructed and evaluated.\n\nSuggestions for Improvement:\n1. The authors should provide more details on how the ZEB benchmark is constructed and evaluated, including the process of sampling image pairs and computing the AUC of the relative pose error.\n2. The paper should provide a more thorough analysis of the computational cost of the framework, including the time and resources required for training and testing.\n3. The authors should investigate the use of other data sources, such as RGBD scans or 3D reconstruction data, to complement the internet videos.\n4. The paper should provide more details on how the GIM framework can be applied to real-world applications, including the potential challenges and limitations.\n\nRecommendation:\nThe paper is well-written and provides a significant contribution to the field of image matching. However, the authors should address the weaknesses and suggestions for improvement to make the paper more comprehensive and impactful. I would recommend this paper for publication in a top-tier conference, but with the condition that the authors address the suggested improvements.\n\nRating: 7.5/10\n$$$",
        "gr_score_with": 0.9292682926829269,
        "gr_score_without": 0.889261744966443,
        "output_without": {
            "num_tokens_scored": 298,
            "num_green_tokens": 265,
            "green_fraction": 0.889261744966443,
            "z_score": -0.6177153866656149,
            "p_value": 0.7316185162379348
        },
        "output_with": {
            "num_tokens_scored": 410,
            "num_green_tokens": 381,
            "green_fraction": 0.9292682926829269,
            "z_score": 1.9756423093120623,
            "p_value": 0.02409765157934451
        }
    },
    {
        "title": "VERA: VECTOR-BASED RANDOM MATRIX ADAPTATION",
        "abstract": "Low-rank adapation (LoRA) is a popular method that reduces the number of trainable parameters when finetuning large language models, but still faces acute storage challenges when scaling to even larger models or deploying numerous peruser or per-task adapted models. In this work, we present Vector-based Random Matrix Adaptation (VeRA)1, which significantly reduces the number of trainable parameters compared to LoRA, yet maintains the same performance. It achieves this by using a single pair of low-rank matrices shared across all layers and learning small scaling vectors instead. We demonstrate its effectiveness on the GLUE and E2E benchmarks, image classification tasks, and show its application in instruction-tuning of 7B and 13B language models.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper presents Vector-based Random Matrix Adaptation (VeRA), a novel parameter-efficient finetuning method for large language models. VeRA reduces the number of trainable parameters compared to the state-of-the-art LoRA method, while maintaining comparable results. The method employs a single pair of frozen random matrices shared across all layers and learns small scaling vectors instead. VeRA achieves significant memory savings, making it suitable for scenarios that require frequent swapping of numerous finetuned models, such as cloud-based AI services personalized for individual users.\n\nStrengths:\n\n1. VeRA significantly reduces the number of trainable parameters compared to LoRA, making it more memory-efficient.\n2. The method achieves comparable results to LoRA on various benchmarks, including GLUE, E2E, and image classification tasks.\n3. VeRA is well-suited for scenarios that require frequent swapping of numerous finetuned models, such as cloud-based AI services personalized for individual users.\n4. The paper provides a thorough analysis of the method's components, including the impact of different initializations and the magnitude of adaptation.\n\nWeaknesses:\n\n1. The paper assumes that the frozen random matrices can be regenerated from a random number generator (RNG) seed, which may not be feasible in all scenarios.\n2. The method's performance may benefit from additional refinements, such as dynamic parameter budget allocation, or different initialization and regularization techniques.\n3. The paper focuses on language and vision models with Transformer architecture, and its applicability to other architectures and domains remains an area for future research.\n\nSuggestions for Improvement:\n\n1. Investigate the feasibility of regenerating frozen random matrices from an RNG seed in various scenarios.\n2. Explore additional refinements, such as dynamic parameter budget allocation, or different initialization and regularization techniques, to improve the method's performance.\n3. Conduct experiments on other architectures and domains to evaluate VeRA's applicability and performance.\n\nRecommendation:\n\nVeRA is a promising parameter-efficient finetuning method that achieves comparable results to LoRA while reducing the number of trainable parameters. The method's memory savings make it suitable for scenarios that require frequent swapping of numerous finetuned models. However, further research is needed to explore the method's limitations and potential areas for improvement. I recommend accepting this paper for publication in a reputable conference, with the suggestion that the authors address the limitations and areas for improvement mentioned above.\n\nRating: 8/10\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper presents Vector-based Random Matrix Adaptation (VeRA), a novel parameter-efficient finetuning method for large language models. VeRA reduces the number of trainable parameters compared to the state-of-the-art LoRA method while maintaining comparable results. The method employs a single pair of low-rank matrices shared across all layers and learns small scaling vectors instead. VeRA achieves significant memory savings and is particularly well-suited for scenarios that require frequent swapping of numerous finetuned models.\n\nStrengths:\n\n1. VeRA achieves a significant reduction in trainable parameters compared to LoRA, making it more memory-efficient.\n2. The method is shown to be effective on various downstream tasks, including language understanding and image classification.\n3. VeRA is particularly well-suited for scenarios that require frequent swapping of numerous finetuned models.\n4. The paper provides a comprehensive comparison with other parameter-efficient adaptation methods.\n\nWeaknesses:\n\n1. The paper assumes that the random frozen matrices can be regenerated from a random number generator (RNG) seed, which may not always be the case.\n2. The method relies on the choice of the initial values for the scaling vectors, which may impact performance.\n3. The paper does not provide a thorough analysis of the trade-offs between trainable parameters and accuracy.\n4. The ablation study is limited to a few experiments and does not provide a comprehensive understanding of the method's components.\n\nSuggestions for Improvement:\n\n1. Provide a more thorough analysis of the trade-offs between trainable parameters and accuracy.\n2. Conduct a more comprehensive ablation study to understand the impact of different components of the method.\n3. Investigate the impact of different initialization schemes for the scaling vectors.\n4. Provide more details on the implementation of VeRA and how it can be integrated into existing frameworks.\n\nRecommendation:\n\nThis paper presents a novel and effective parameter-efficient finetuning method for large language models. While there are some limitations to the paper, the method shows promising results and has the potential to be widely adopted. I recommend this paper for publication in a reputable conference or journal.\n\nOverall, the paper is well-written and easy to follow. The authors provide a clear and concise overview of the method and its components. The experiments are thorough and provide a good comparison with other parameter-efficient adaptation methods. However, there are some areas for improvement, and I would like to see more comprehensive analysis and ablation studies in future work.\n\nScore: 8/10\n\nRecommendation: Accept",
        "gr_score_with": 0.936,
        "gr_score_without": 0.8977272727272727,
        "output_without": {
            "num_tokens_scored": 352,
            "num_green_tokens": 316,
            "green_fraction": 0.8977272727272727,
            "z_score": -0.1419367996132358,
            "p_value": 0.556435036661808
        },
        "output_with": {
            "num_tokens_scored": 375,
            "num_green_tokens": 351,
            "green_fraction": 0.936,
            "z_score": 2.3239591105410846,
            "p_value": 0.010063842829889898
        }
    },
    {
        "title": "FANTASTIC GENERALIZATION MEASURES",
        "abstract": "We study the notion of a generalization bound being uniformly tight, meaning that the difference between the bound and the population loss is small for all learning algorithms and all population distributions. Numerous generalization bounds have been proposed in the literature as potential explanations for the ability of neural networks to generalize in the overparameterized setting. However, in their paper \u201cFantastic Generalization Measures and Where to Find Them,\u201d Jiang et al. (2020) examine more than a dozen generalization bounds, and show empirically that none of them are uniformly tight. This raises the question of whether uniformly-tight generalization bounds are at all possible in the overparameterized setting. We consider two types of generalization bounds: (1) bounds that may depend on the training set and the learned hypothesis (e.g., margin bounds). We prove mathematically that no such bound can be uniformly tight in the overparameterized setting; (2) bounds that may in addition also depend on the learning algorithm (e.g., stability bounds). For these bounds, we show a trade-off between the algorithm\u2019s performance and the bound\u2019s tightness. Namely, if the algorithm achieves good accuracy on certain distributions, then no generalization bound can be uniformly tight for it in the overparameterized setting. We explain how these formal results can, in our view, inform research on generalization bounds for neural networks, while stressing that other interpretations of these results are also possible.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper studies the notion of a generalization bound being uniformly tight, meaning that the difference between the bound and the population loss is small for all learning algorithms and all population distributions. The authors examine two types of generalization bounds: (1) bounds that may depend on the training set and the learned hypothesis, and (2) bounds that may also depend on the learning algorithm. They prove mathematically that no generalization bound of the first type can be uniformly tight in the overparameterized setting, and establish a trade-off between learning performance and estimability for the second type of bounds.\n\nStrengths:\n\n* The paper provides a rigorous and formal analysis of the notion of uniformly tight generalization bounds.\n* The authors introduce a framework for understanding the limitations of generalization bounds in the overparameterized setting.\n* The paper presents several theorems and lemmas that provide a deeper understanding of the relationships between learning performance, estimability, and generalization bounds.\n\nWeaknesses:\n\n* The paper assumes a high level of mathematical background, which may make it challenging for readers without a strong background in machine learning and theoretical computer science.\n* The authors do not provide a comprehensive review of existing generalization bounds and their limitations, which may make it difficult for readers to understand the significance of their results.\n* The paper's conclusions and implications may be subject to interpretation, and the authors acknowledge that different scholarly positions exist on this matter.\n\nSuggestions for Improvement:\n\n* The authors could provide a more accessible introduction to the mathematical framework and notation used in the paper.\n* The paper could benefit from a more comprehensive review of existing generalization bounds and their limitations, which would provide context for the authors' results.\n* The authors could provide more concrete examples and illustrations to demonstrate the implications of their results and make the paper more engaging for readers.\n\nRecommendation:\n\nThe paper provides a valuable contribution to the field of machine learning and theoretical computer science by shedding light on the limitations of generalization bounds in the overparameterized setting. The authors' formal analysis and rigorous proofs provide a solid foundation for understanding the relationships between learning performance, estimability, and generalization bounds. However, the paper's assumptions and conclusions may be subject to interpretation, and the authors could benefit from providing a more comprehensive review of existing generalization bounds and their limitations. Overall, the paper is well-written and well-structured, and it is a valuable contribution to the field.\n\nRecommendation for Publication: Yes\n\nRecommendation for Future Research:\n\n* Investigate the implications of the authors' results for existing generalization bounds and their limitations.\n* Explore the relationships between learning performance, estimability, and generalization bounds in more detail.\n* Develop new generalization bounds that take into account the limitations and trade-offs identified by the authors.\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper studies the concept of generalization bounds in the context of neural networks, specifically in the overparameterized setting. The authors investigate whether it is possible to obtain generalization bounds that are uniformly tight, meaning that they are tight for all learning algorithms and population distributions. The paper provides two main results: (1) a negative result showing that algorithm-independent generalization bounds cannot be uniformly tight in the overparameterized setting, and (2) a trade-off between learnability and estimability, which implies that algorithm-dependent generalization bounds are also limited.\n\nStrengths:\n\n* The paper provides a comprehensive and rigorous treatment of the concept of generalization bounds in the overparameterized setting.\n* The authors present two main results, which are well-motivated and have important implications for the field of machine learning.\n* The paper includes a thorough discussion of related work and provides a clear overview of the current state of the art.\n* The authors provide a concrete example of a hypothesis class and a set of algorithms to illustrate their results.\n\nWeaknesses:\n\n* The paper assumes a high level of mathematical background, which may make it challenging for readers without a strong background in machine learning and statistics.\n* The authors do not provide a clear explanation of why the overparameterized setting is relevant to neural networks, which may make the paper difficult to understand for readers without a strong background in neural networks.\n* The paper does not discuss the implications of their results for the design of neural networks, which may limit the paper's impact.\n\nSuggestions for Improvement:\n\n* Provide a more detailed explanation of the overparameterized setting and its relevance to neural networks.\n* Consider adding more concrete examples or illustrations to help readers understand the results.\n* Discuss the implications of the results for the design of neural networks, such as the choice of architecture or hyperparameters.\n* Consider providing a more detailed discussion of the limitations of the paper, such as the assumptions made about the hypothesis class and the algorithms.\n\nRecommendation:\n\nThe paper is well-written and provides a comprehensive treatment of the concept of generalization bounds in the overparameterized setting. The authors present two main results, which are well-motivated and have important implications for the field of machine learning. However, the paper assumes a high level of mathematical background, which may make it challenging for readers without a strong background in machine learning and statistics. Therefore, I recommend this paper for readers with a strong background in machine learning and statistics, but with the caveat that it may be challenging for readers without a strong background in the field.\n\nRecommendation: Accept\n\nRating: 8/10\n\nReviewer: [Your Name]\n\nDate: [Today's Date]\n\n$$$",
        "gr_score_with": 0.9317507418397626,
        "gr_score_without": 0.914364640883978,
        "output_without": {
            "num_tokens_scored": 362,
            "num_green_tokens": 331,
            "green_fraction": 0.914364640883978,
            "z_score": 0.9112049389111346,
            "p_value": 0.181093701116102
        },
        "output_with": {
            "num_tokens_scored": 337,
            "num_green_tokens": 314,
            "green_fraction": 0.9317507418397626,
            "z_score": 1.9430510450725738,
            "p_value": 0.026004995562295772
        }
    },
    {
        "title": "STEVE-EYE: EQUIPPING LLM-BASED EMBOD-",
        "abstract": "Recent studies have presented compelling evidence that large language models (LLMs) can equip embodied agents with the self-driven capability to interact with the world, which marks an initial step toward versatile robotics. However, these efforts tend to overlook the visual richness of open worlds, rendering the entire interactive process akin to \u201ca blindfolded text-based game.\u201d Consequently, LLMbased agents frequently encounter challenges in intuitively comprehending their surroundings and producing responses that are easy to understand. In this paper, we propose Steve-Eye, an end-to-end trained large multimodal model to address this limitation. Steve-Eye integrates the LLM with a visual encoder to process visual-text inputs and generate multimodal feedback. We adopt a semi-automatic strategy to collect an extensive dataset comprising 850K open-world instruction pairs, enabling our model to encompass three essential functions for an agent: multimodal perception, foundational knowledge base, and skill prediction and planning. Lastly, we develop three open-world evaluation benchmarks, then carry out experiments from a wide range of perspectives to validate our model\u2019s capability to strategically act and plan. Codes and datasets will be released.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes Steve-Eye, a large multimodal model that enables large language model (LLM)-based embodied agents to interact with the open world via visual-text interfaces. Steve-Eye is equipped with three essential functions: multimodal perception, foundational knowledge base, and skill prediction and planning. The authors construct an extensive dataset of 850K open-world instruction pairs to train Steve-Eye and develop three open-world evaluation benchmarks to validate the model's capability to strategically act and plan.\n\nStrengths:\n\n1. The paper presents a novel approach to multimodal interaction in open-world environments, addressing the limitations of text-only agents.\n2. The proposed model, Steve-Eye, demonstrates improved performance in multimodal perception, foundational knowledge question answering, and skill prediction and planning.\n3. The authors provide a comprehensive evaluation of the model's performance on three open-world benchmarks, including environmental visual captioning, foundational knowledge question answering, and skill prediction and planning.\n\nWeaknesses:\n\n1. The paper relies heavily on the use of pre-trained LLMs and visual encoders, which may limit the model's ability to generalize to new tasks and environments.\n2. The dataset collection process is labor-intensive and requires significant human annotation effort, which may not be scalable for larger datasets.\n3. The paper does not provide a thorough analysis of the model's limitations and failure cases, which may be essential for understanding its robustness and reliability.\n\nSuggestions for Improvement:\n\n1. Investigate the use of more robust and generalizable pre-trained models that can handle a wide range of tasks and environments.\n2. Explore more efficient and scalable methods for dataset collection, such as active learning or transfer learning.\n3. Conduct a more comprehensive analysis of the model's limitations and failure cases to better understand its robustness and reliability.\n\nRecommendation:\n\nThis paper presents a novel and promising approach to multimodal interaction in open-world environments. While there are some limitations and areas for improvement, the proposed model demonstrates improved performance on three open-world benchmarks. I recommend this paper for publication in a reputable conference, with the understanding that the authors will address the limitations and suggestions for improvement outlined above.\n\nRating: 7.5/10\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes Steve-Eye, a large multimodal model that enables large language model (LLM)-based embodied agents to engage with the open world via visual-text interfaces. Steve-Eye is equipped with three indispensable functions: (1) multimodal perception; (2) foundational knowledge base; and (3) skill prediction and planning. The authors develop a semi-automatic strategy to collect an extensive dataset comprising 850K open-world instruction pairs and adopt a two-stage strategy to train the model. Experiments on three open-world benchmarks demonstrate that Steve-Eye outperforms LLM-based agents in open-world setups.\n\nStrengths:\n\n1. The paper proposes a novel approach to enable LLM-based agents to engage with the open world via visual-text interfaces, which is a significant contribution to the field of embodied AI.\n2. The authors develop a semi-automatic strategy to collect a large-scale dataset, which is essential for training a multimodal model.\n3. The paper presents a comprehensive evaluation of the proposed model on three open-world benchmarks, demonstrating its advantages over a wide range of perspectives.\n\nWeaknesses:\n\n1. The paper assumes that the visual encoder is pre-trained, which may not be the case in practice. The authors should provide more details on how to pre-train the visual encoder.\n2. The paper does not provide a thorough comparison with other state-of-the-art multimodal models, which makes it difficult to evaluate the novelty and effectiveness of the proposed approach.\n3. The paper mentions that the model still falls short in fine-grained reasoning tasks, which requires further investigation and improvement.\n\nSuggestions for Improvement:\n\n1. Provide more details on how to pre-train the visual encoder and its impact on the performance of the proposed model.\n2. Conduct a more thorough comparison with other state-of-the-art multimodal models to evaluate the novelty and effectiveness of the proposed approach.\n3. Investigate and improve the fine-grained reasoning capabilities of the proposed model.\n\nRecommendation:\n\nThe paper presents a novel approach to enable LLM-based agents to engage with the open world via visual-text interfaces. While there are some limitations and areas for improvement, the paper demonstrates the potential of the proposed approach and provides a comprehensive evaluation on three open-world benchmarks. With further investigation and improvement, the proposed model has the potential to become a state-of-the-art multimodal model for embodied AI applications.\n\n$$$",
        "gr_score_with": 0.95625,
        "gr_score_without": 0.933933933933934,
        "output_without": {
            "num_tokens_scored": 333,
            "num_green_tokens": 311,
            "green_fraction": 0.933933933933934,
            "z_score": 2.0642817122619426,
            "p_value": 0.019495506958654468
        },
        "output_with": {
            "num_tokens_scored": 320,
            "num_green_tokens": 306,
            "green_fraction": 0.95625,
            "z_score": 3.35424144011788,
            "p_value": 0.00039791444925883567
        }
    },
    {
        "title": "PERCEPTUAL GROUP TOKENIZER: BUILDING PERCEPTION WITH ITERATIVE GROUPING",
        "abstract": "Human visual recognition system shows astonishing capability of compressing visual information into a set of tokens containing rich representations without label supervision. One critical driving principle behind it is perceptual grouping (Palmer, 2002; Wagemans et al., 2012; Herzog, 2018). Despite being widely used in computer vision in the early 2010s, it remains a mystery whether perceptual grouping can be leveraged to derive a neural visual recognition backbone that generates as powerful representations. In this paper, we propose the Perceptual Group Tokenizer, a model that entirely relies on grouping operations to extract visual features and perform self-supervised representation learning, where a series of grouping operations are used to iteratively hypothesize the context for pixels or superpixels to refine feature representations. We show that the proposed model can achieve competitive performance compared to state-of-the-art vision architectures, and inherits desirable properties including adaptive computation without re-training, and interpretability. Specifically, Perceptual Group Tokenizer achieves 80.3% on ImageNet-1K self-supervised learning benchmark with linear probe evaluation, establishing a new milestone for this paradigm.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\nThe paper proposes a novel visual recognition architecture called Perceptual Group Tokenizer (PGT), which entirely relies on perceptual grouping principles to extract visual features and perform self-supervised representation learning. The model consists of a series of grouping operations that iteratively hypothesize the context for pixels or superpixels to refine feature representations. The authors show that PGT achieves competitive performance compared to state-of-the-art vision architectures on self-supervised learning benchmarks and inherits desirable properties such as adaptive computation and high model interpretability.\n\nStrengths:\n1. The paper proposes a novel and innovative approach to visual recognition, which is based on perceptual grouping principles.\n2. The model achieves competitive performance compared to state-of-the-art vision architectures on self-supervised learning benchmarks.\n3. The authors provide a thorough analysis of the model's properties, including adaptive computation and high model interpretability.\n4. The paper provides a clear and concise explanation of the model's architecture and training procedure.\n\nWeaknesses:\n1. The paper assumes that the reader is familiar with the concept of perceptual grouping and its applications in computer vision.\n2. The model's performance on other tasks, such as object detection and segmentation, is not evaluated.\n3. The paper does not provide a thorough comparison with other state-of-the-art models, such as ViT and ResNet.\n4. The model's computational cost is relatively high due to the iterative grouping processes.\n\nSuggestions for Improvement:\n1. Provide a more detailed explanation of the perceptual grouping principles and their applications in computer vision.\n2. Evaluate the model's performance on other tasks, such as object detection and segmentation.\n3. Compare the model's performance with other state-of-the-art models, such as ViT and ResNet.\n4. Explore ways to reduce the model's computational cost, such as using more efficient grouping operations.\n\nRecommendation:\nThe paper proposes a novel and innovative approach to visual recognition, which is based on perceptual grouping principles. The model achieves competitive performance compared to state-of-the-art vision architectures on self-supervised learning benchmarks and inherits desirable properties such as adaptive computation and high model interpretability. However, the paper assumes that the reader is familiar with the concept of perceptual grouping and its applications in computer vision, and the model's performance on other tasks is not evaluated. Therefore, I recommend that the authors provide a more detailed explanation of the perceptual grouping principles and their applications in computer vision, evaluate the model's performance on other tasks, and compare the model's performance with other state-of-the-art models.\n\nScore: 8/10\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\nThe paper proposes a novel visual recognition architecture called Perceptual Group Tokenizer (PGT) that relies entirely on perceptual grouping principles for self-supervised representation learning. PGT achieves competitive performance on the ImageNet-1K benchmark and has desirable properties such as adaptive computation and high model interpretability.\n\nStrengths:\n1. The paper presents a novel approach to visual recognition that is based on perceptual grouping principles, which is a promising direction for future research.\n2. The proposed model, PGT, shows strong performance on the ImageNet-1K benchmark with linear probe evaluation, which is a challenging task.\n3. The paper highlights the desirable properties of PGT, including adaptive computation and high model interpretability, which make it a valuable contribution to the field.\n4. The authors provide a thorough analysis of the design space of PGT and explore various ablation studies, which provides valuable insights into the model's behavior.\n\nWeaknesses:\n1. The paper assumes that the input image is divided into small patches, which may not be the most efficient way to represent images, especially for large images.\n2. The iterative grouping process in PGT can be computationally expensive, which may limit its practical applications.\n3. The paper does not provide a thorough comparison with other state-of-the-art models, which makes it difficult to evaluate the performance of PGT in a broader context.\n4. The paper assumes that the grouping operation can automatically learn and emerge both pairwise and higher-order information exchange, which is a strong assumption that may not always hold.\n\nSuggestions for Improvement:\n1. The authors should provide a more thorough comparison with other state-of-the-art models, including those that use self-attention mechanisms.\n2. The paper should provide a more detailed analysis of the computational cost of the iterative grouping process and explore ways to reduce it.\n3. The authors should provide more insights into the limitations of the proposed model and how it can be improved.\n4. The paper should provide more experimental results on downstream tasks, such as object detection and segmentation, to evaluate the generalizability of the proposed model.\n\nRecommendation:\nThe paper presents a novel approach to visual recognition that is based on perceptual grouping principles, which is a promising direction for future research. The proposed model, PGT, shows strong performance on the ImageNet-1K benchmark and has desirable properties such as adaptive computation and high model interpretability. However, the paper assumes that the input image is divided into small patches, which may not be the most efficient way to represent images, and the iterative grouping process can be computationally expensive. Therefore, I recommend that the authors provide a more thorough comparison with other state-of-the-art models and explore ways to reduce the computational cost of the iterative grouping process.\n\nOverall, I believe that the paper presents a valuable contribution to the field of visual recognition and provides a promising direction for future research.",
        "gr_score_with": 0.9292035398230089,
        "gr_score_without": 0.9071428571428571,
        "output_without": {
            "num_tokens_scored": 280,
            "num_green_tokens": 254,
            "green_fraction": 0.9071428571428571,
            "z_score": 0.39857796800869966,
            "p_value": 0.3451020991036301
        },
        "output_with": {
            "num_tokens_scored": 339,
            "num_green_tokens": 315,
            "green_fraction": 0.9292035398230089,
            "z_score": 1.7924805365131784,
            "p_value": 0.03652801210510132
        }
    },
    {
        "title": "FOSI: Hybrid First and Second Order Optimization",
        "abstract": "Popular machine learning approaches forgo second-order information due to the difficulty of computing curvature in high dimensions. We present FOSI, a novel meta-algorithm that improves the performance of any base first-order optimizer by efficiently incorporating second-order information during the optimization process. In each iteration, FOSI implicitly splits the function into two quadratic functions defined on orthogonal subspaces, then uses a second-order method to minimize the first, and the base optimizer to minimize the other. We formally analyze FOSI\u2019s convergence and the conditions under which it improves a base optimizer. Our empirical evaluation demonstrates that FOSI improves the convergence rate and optimization time of first-order methods such as Heavy-Ball and Adam, and outperforms second-order methods (K-FAC and L-BFGS).",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes FOSI, a hybrid optimization algorithm that combines a first-order base optimizer with Newton's method to improve the convergence of any base first-order optimizer. FOSI iteratively splits the optimization problem into two quadratic problems on orthogonal subspaces, uses Newton's method to minimize one, and the base optimizer to minimize the other. The algorithm is designed to efficiently incorporate second-order information without computing the entire Hessian, making it suitable for large-scale optimization problems. The paper formally analyzes FOSI's convergence and the conditions under which it improves a base optimizer. Empirical evaluation demonstrates that FOSI improves the convergence rate and optimization time of first-order methods and outperforms second-order methods on various deep neural network training tasks.\n\nStrengths:\n\n1. FOSI is a hybrid optimization algorithm that combines the benefits of first-order and second-order methods, making it a robust and efficient optimization technique.\n2. The algorithm is designed to efficiently incorporate second-order information without computing the entire Hessian, making it suitable for large-scale optimization problems.\n3. The paper provides a thorough analysis of FOSI's convergence and the conditions under which it improves a base optimizer.\n4. Empirical evaluation demonstrates that FOSI improves the convergence rate and optimization time of first-order methods and outperforms second-order methods on various deep neural network training tasks.\n\nWeaknesses:\n\n1. The algorithm requires the number of Lanczos iterations (m) to be set, which can be a hyperparameter that needs to be tuned.\n2. The paper assumes that the Hessian is symmetric and positive definite, which may not be the case in all optimization problems.\n3. The algorithm requires the use of a base first-order optimizer, which may not be the best choice for all optimization problems.\n4. The paper does not provide a thorough analysis of the computational complexity of FOSI.\n\nSuggestions for Improvement:\n\n1. Investigate methods for automatically tuning the number of Lanczos iterations (m) and other hyperparameters of FOSI.\n2. Consider relaxing the assumption that the Hessian is symmetric and positive definite to make FOSI more applicable to a wider range of optimization problems.\n3. Investigate the use of other base first-order optimizers, such as stochastic gradient descent, to see if they can be improved by FOSI.\n4. Provide a thorough analysis of the computational complexity of FOSI and compare it to other optimization algorithms.\n\nRecommendation:\n\nFOSI is a promising optimization algorithm that combines the benefits of first-order and second-order methods. While there are some limitations and areas for improvement, the algorithm shows great potential for improving the convergence rate and optimization time of first-order methods and outperforming second-order methods on various deep neural network training tasks. Therefore, I recommend accepting this paper for publication in a top-tier conference or journal.\n\nRating: 8/10\n\nReviewer's Confidence: 9/10\n\nReviewer's Expertise: Optimization algorithms, machine learning, deep learning.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes FOSI, a hybrid optimization algorithm that improves the performance of any base first-order optimizer by incorporating second-order information. FOSI iteratively splits the optimization problem into pairs of quadratic problems on orthogonal subspaces and uses a second-order method to minimize one and the base optimizer to minimize the other. The paper provides a detailed description of the FOSI algorithm, a thorough spectral analysis of its preconditioner, and convergence guarantees in the stochastic setting. The empirical evaluation demonstrates that FOSI improves the convergence rate and optimization time of first-order methods such as Heavy-Ball and Adam, and outperforms second-order methods (K-FAC and L-BFGS).\n\nStrengths:\n\n1. FOSI is a hybrid optimization algorithm that improves the performance of any base first-order optimizer by incorporating second-order information.\n2. The paper provides a detailed description of the FOSI algorithm and a thorough spectral analysis of its preconditioner.\n3. The empirical evaluation demonstrates that FOSI improves the convergence rate and optimization time of first-order methods and outperforms second-order methods.\n4. The paper provides convergence guarantees in the stochastic setting, which is a significant contribution.\n\nWeaknesses:\n\n1. The paper assumes that the Hessian of the objective function is available, which may not be the case in practice.\n2. The paper does not provide a detailed analysis of the computational complexity of FOSI.\n3. The paper assumes that the ESE procedure provides accurate estimates of the extreme eigenvalues and eigenvectors of the Hessian, which may not be the case in practice.\n\nSuggestions for Improvement:\n\n1. Provide a detailed analysis of the computational complexity of FOSI.\n2. Investigate the robustness of FOSI to inaccurate estimates of the extreme eigenvalues and eigenvectors of the Hessian.\n3. Provide more experimental results to demonstrate the effectiveness of FOSI on a wider range of optimization problems.\n4. Investigate the use of FOSI in conjunction with other optimization algorithms to further improve its performance.\n\nRecommendation:\n\nThe paper proposes a novel and effective optimization algorithm that improves the performance of first-order methods by incorporating second-order information. The empirical evaluation demonstrates the effectiveness of FOSI, and the convergence guarantees in the stochastic setting are a significant contribution. However, the paper assumes that the Hessian of the objective function is available, and the computational complexity of FOSI is not analyzed. Therefore, I recommend that the authors provide a detailed analysis of the computational complexity of FOSI and investigate the robustness of FOSI to inaccurate estimates of the extreme eigenvalues and eigenvectors of the Hessian.\n\nOverall, the paper is well-written, and the results are impressive. However, to make the paper more comprehensive, the authors should address the limitations and suggestions for improvement mentioned above.\n\n$$$\nNote: The reviewer has carefully read the paper and provided a detailed review. However, the review is not perfect, and the reviewer may have missed some important details. The author should carefully read the review and address any concerns or suggestions for improvement.",
        "gr_score_with": 0.9532163742690059,
        "gr_score_without": 0.9260273972602739,
        "output_without": {
            "num_tokens_scored": 365,
            "num_green_tokens": 338,
            "green_fraction": 0.9260273972602739,
            "z_score": 1.6576847239185242,
            "p_value": 0.04869055937555084
        },
        "output_with": {
            "num_tokens_scored": 342,
            "num_green_tokens": 326,
            "green_fraction": 0.9532163742690059,
            "z_score": 3.280624407952807,
            "p_value": 0.0005178878691633204
        }
    },
    {
        "title": "UNLEASHING LARGE-SCALE VIDEO GENERATIVE PRE-TRAINING FOR VISUAL ROBOT MANIPULATION",
        "abstract": "Generative pre-trained models have demonstrated remarkable effectiveness in language and vision domains by learning useful representations. In this paper, we extend the scope of this effectiveness by showing that visual robot manipulation can significantly benefit from large-scale video generative pre-training. We introduce GR-1, a GPT-style model designed for multi-task language-conditioned visual robot manipulation. GR-1 takes as inputs a language instruction, a sequence of observation images, and a sequence of robot states. It predicts robot actions as well as future images in an end-to-end manner. Thanks to a flexible design, GR-1 can be seamlessly finetuned on robot data after pre-trained on a large-scale video dataset. We perform extensive experiments on the challenging CALVIN benchmark and a real robot. On CALVIN benchmark, our method outperforms state-of-the-art baseline methods and improves the success rate from 88.9% to 94.9%. In the setting of zero-shot unseen scene generalization, GR-1 improves the success rate from 53.3% to 85.4%. In real robot experiments, GR-1 also outperforms baseline methods and shows strong potentials in generalization to unseen scenes and objects. We provide inaugural evidence that a unified GPT-style transformer, augmented with large-scale video generative pre-training, exhibits remarkable generalization to multi-task visual robot manipulation. Project page: https://GR1-Manipulation.github.io",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel approach to visual robot manipulation by leveraging large-scale video generative pre-training. The authors introduce GR-1, a GPT-style transformer model that takes as inputs a language instruction, a sequence of observation images, and a sequence of robot states, and predicts robot actions and future images in an end-to-end manner. GR-1 is first pre-trained on language-conditioned video prediction with a large-scale video dataset and then finetuned on robot data. The authors demonstrate the effectiveness of GR-1 on the challenging CALVIN benchmark and a real robot, outperforming state-of-the-art baseline methods in various settings, including multi-task learning, zero-shot unseen scene generalization, small dataset, and zero-shot unseen language generalization.\n\nStrengths:\n\n* The paper presents a novel approach to visual robot manipulation by leveraging large-scale video generative pre-training, which is a promising direction for future research.\n* The authors demonstrate the effectiveness of GR-1 on the challenging CALVIN benchmark and a real robot, outperforming state-of-the-art baseline methods in various settings.\n* The paper provides a comprehensive evaluation of GR-1, including multi-task learning, zero-shot unseen scene generalization, small dataset, and zero-shot unseen language generalization.\n\nWeaknesses:\n\n* The paper relies heavily on pre-training on a large-scale video dataset, which may not be feasible for all applications or domains.\n* The authors do not provide a thorough analysis of the trade-offs between pre-training and finetuning, which may be important for practical applications.\n* The paper assumes access to a large-scale video dataset, which may not be available for all researchers or applications.\n\nSuggestions for Improvement:\n\n* Provide a more detailed analysis of the trade-offs between pre-training and finetuning, including the impact on performance, computational resources, and data requirements.\n* Explore alternative approaches to pre-training, such as using smaller datasets or different types of data, to make the method more widely applicable.\n* Provide more information about the scalability of GR-1, including the computational resources required for training and inference.\n\nRecommendation:\n\nThe paper presents a novel and promising approach to visual robot manipulation, and the authors demonstrate its effectiveness on challenging benchmarks. However, the paper relies heavily on pre-training on a large-scale video dataset, and the trade-offs between pre-training and finetuning are not thoroughly analyzed. To make the method more widely applicable and scalable, the authors should explore alternative approaches to pre-training and provide a more detailed analysis of the trade-offs between pre-training and finetuning. With these improvements, the paper has the potential to make a significant impact in the field of visual robot manipulation.\n\nRating: 7/10\n\nRecommendation for Publication: Accept with revisions.",
        "peer_review_with_watermark": "$$$\n\nPaper Summary:\n\nThe paper proposes a novel approach to visual robot manipulation by leveraging large-scale video generative pre-training. The authors introduce GR-1, a GPT-style transformer model that takes as inputs a language instruction, a sequence of observation images, and a sequence of robot states, and predicts robot actions and future images in an end-to-end manner. GR-1 is first pre-trained on language-conditioned video prediction with a large-scale video dataset and then finetuned on robot data. The authors demonstrate the effectiveness of GR-1 on the challenging CALVIN benchmark and a real robot, outperforming state-of-the-art baseline methods in various settings, including multi-task learning, zero-shot unseen scene generalization, small dataset, and zero-shot unseen language generalization.\n\nStrengths:\n\n* The paper presents a novel approach to visual robot manipulation that leverages large-scale video generative pre-training.\n* The authors demonstrate the effectiveness of GR-1 on the challenging CALVIN benchmark and a real robot.\n* The paper provides extensive experiments and quantitative results to support the claims.\n* The authors discuss the potential of GR-1 in various settings, including multi-task learning, zero-shot unseen scene generalization, small dataset, and zero-shot unseen language generalization.\n\nWeaknesses:\n\n* The paper assumes access to a large-scale video dataset, which may not be available in all scenarios.\n* The authors do not provide a detailed analysis of the video prediction performance of GR-1.\n* The paper does not discuss the potential limitations of GR-1, such as its sensitivity to noise or its performance in complex scenarios.\n\nSuggestions for Improvement:\n\n* The authors should provide a more detailed analysis of the video prediction performance of GR-1.\n* The paper should discuss the potential limitations of GR-1 and provide suggestions for future work to address these limitations.\n* The authors should provide more information about the Ego4D dataset and the CALVIN benchmark, including the size of the dataset and the complexity of the tasks.\n\nRecommendation:\n\nThe paper presents a novel and effective approach to visual robot manipulation that leverages large-scale video generative pre-training. The authors demonstrate the effectiveness of GR-1 on the challenging CALVIN benchmark and a real robot, and provide extensive experiments and quantitative results to support the claims. However, the paper assumes access to a large-scale video dataset, and the authors do not provide a detailed analysis of the video prediction performance of GR-1. Therefore, the paper is suitable for publication in a top-tier conference, but the authors should address the limitations mentioned above to make the paper more comprehensive.\n\nRating: 8.5/10\n\nRecommendation for publication: Yes\n\n$$$",
        "gr_score_with": 0.9455128205128205,
        "gr_score_without": 0.9262536873156342,
        "output_without": {
            "num_tokens_scored": 339,
            "num_green_tokens": 314,
            "green_fraction": 0.9262536873156342,
            "z_score": 1.6114412303707903,
            "p_value": 0.05354179341554227
        },
        "output_with": {
            "num_tokens_scored": 312,
            "num_green_tokens": 295,
            "green_fraction": 0.9455128205128205,
            "z_score": 2.67986879619925,
            "p_value": 0.0036825511027531012
        }
    },
    {
        "title": "DOUBLY ROBUST INSTANCE-REWEIGHTED ADVERSARIAL TRAINING",
        "abstract": "Assigning importance weights to adversarial data has achieved great success in training adversarially robust networks under limited model capacity. However, existing instance-reweighted adversarial training (AT) methods heavily depend on heuristics and/or geometric interpretations to determine those importance weights, making these algorithms lack rigorous theoretical justification/guarantee. Moreover, recent research has shown that adversarial training suffers from a severe non-uniform robust performance across the training distribution, e.g., data points belonging to some classes can be much more vulnerable to adversarial attacks than others. To address both issues, in this paper, we propose a novel doubly-robust instance reweighted AT framework, which allows to obtain the importance weights via exploring distributionally robust optimization (DRO) techniques, and at the same time boosts the robustness on the most vulnerable examples. In particular, our importance weights are obtained by optimizing the KL-divergence regularized loss function, which allows us to devise new algorithms with a theoretical convergence guarantee. Experiments on standard classification datasets demonstrate that our proposed approach outperforms related state-of-the-art baseline methods in terms of average robust performance, and at the same time improves the robustness against attacks on the weakest data points. Codes can be found in the Supplement.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel doubly robust instance reweighted adversarial training framework, which combines distributionally robust optimization (DRO) and bilevel optimization to determine instance weights for adversarial training in a theoretically grounded way. The framework addresses the non-uniform issues of traditional adversarial training by boosting the robust performance of the most vulnerable examples. The authors also develop a novel algorithm based on implicit function theorem and tracking a running average of the outer level function values to solve the doubly robust optimization problem.\n\nStrengths:\n\n* The paper provides a theoretically grounded approach to determine instance weights for adversarial training, which is a significant improvement over existing heuristics-based methods.\n* The proposed framework addresses the non-uniform issues of traditional adversarial training by boosting the robust performance of the most vulnerable examples.\n* The authors develop a novel algorithm based on implicit function theorem and tracking a running average of the outer level function values to solve the doubly robust optimization problem.\n* The paper provides experimental results on standard benchmarks, demonstrating the effectiveness of the proposed framework.\n\nWeaknesses:\n\n* The paper assumes that the attack loss function \u2113\u2032(\u00b7; \u03b8) is twice differentiable, which may not be the case in practice.\n* The authors use a log-barrier penalty method to penalize the linear constraint into the attack objective, which may not be effective in all cases.\n* The paper does not provide a comprehensive comparison with other existing methods, such as robust overfitting mitigation methods.\n* The experimental results are limited to standard benchmarks and do not provide a thorough analysis of the robustness of the proposed framework against different types of attacks.\n\nSuggestions for Improvement:\n\n* Provide a more comprehensive comparison with other existing methods, including robust overfitting mitigation methods.\n* Analyze the robustness of the proposed framework against different types of attacks, such as white-box and black-box attacks.\n* Provide more experimental results on other benchmarks and datasets to demonstrate the effectiveness of the proposed framework.\n* Consider using more robust optimization techniques, such as robust gradient descent, to improve the stability of the optimization process.\n\nRecommendation:\n\nThe paper provides a theoretically grounded approach to determine instance weights for adversarial training, which is a significant improvement over existing heuristics-based methods. However, the paper assumes that the attack loss function \u2113\u2032(\u00b7; \u03b8) is twice differentiable, which may not be the case in practice. Additionally, the authors use a log-barrier penalty method to penalize the linear constraint into the attack objective, which may not be effective in all cases. Therefore, I recommend that the authors provide a more comprehensive comparison with other existing methods, analyze the robustness of the proposed framework against different types of attacks, and provide more experimental results on other benchmarks and datasets to demonstrate the effectiveness of the proposed framework.\n\nOverall, the paper provides a promising approach to adversarial training, and with further improvements, it has the potential to become a leading method in the field.\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel doubly robust instance reweighted adversarial training framework, which combines distributionally robust optimization (DRO) and bilevel optimization to determine instance weights for adversarial training in a theoretically grounded way. The framework addresses the non-uniform issues of traditional adversarial training by boosting the robust performance of the most vulnerable examples. The authors also develop a novel algorithm based on implicit function theorem and tracking a running average of the outer level function values. The proposed framework leads to a new finite-sum compositional bilevel optimization problem, which can be of great interest to the optimization community.\n\nStrengths:\n\n1. The paper proposes a novel and theoretically grounded approach to instance reweighted adversarial training, which addresses the non-uniform issues of traditional adversarial training.\n2. The authors develop a novel algorithm based on implicit function theorem and tracking a running average of the outer level function values, which provides a theoretical guarantee for the proposed framework.\n3. The paper provides extensive experimental evaluations on standard benchmarks, which demonstrate the effectiveness of the proposed framework.\n4. The authors provide a comprehensive review of related work and provide a clear explanation of the proposed framework and its benefits.\n\nWeaknesses:\n\n1. The paper assumes that the adversarial loss function is twice differentiable, which may not be the case in practice.\n2. The authors assume that the inner level problem has a unique minimizer, which may not be the case in practice.\n3. The paper does not provide a detailed analysis of the computational complexity of the proposed algorithm.\n4. The authors do not provide a comparison with other instance reweighted adversarial training methods that do not use DRO.\n\nSuggestions for Improvement:\n\n1. The authors should provide a more detailed analysis of the assumptions made in the paper, and provide a more robust analysis of the proposed framework.\n2. The paper should provide a more detailed comparison with other instance reweighted adversarial training methods that do not use DRO.\n3. The authors should provide a more detailed analysis of the computational complexity of the proposed algorithm, and provide a more efficient implementation.\n4. The paper should provide a more detailed analysis of the experimental evaluations, and provide more insights into the benefits of the proposed framework.\n\nRecommendation:\n\nThe paper proposes a novel and theoretically grounded approach to instance reweighted adversarial training, which addresses the non-uniform issues of traditional adversarial training. The authors develop a novel algorithm based on implicit function theorem and tracking a running average of the outer level function values, which provides a theoretical guarantee for the proposed framework. The paper provides extensive experimental evaluations on standard benchmarks, which demonstrate the effectiveness of the proposed framework. However, the paper assumes that the adversarial loss function is twice differentiable, which may not be the case in practice. The authors should provide a more detailed analysis of the assumptions made in the paper, and provide a more robust analysis of the proposed framework. Overall, the paper is well-written and provides a comprehensive review of related work. I recommend the paper for publication in a top-tier conference.\n\n$$$",
        "gr_score_with": 0.9652777777777778,
        "gr_score_without": 0.9278996865203761,
        "output_without": {
            "num_tokens_scored": 319,
            "num_green_tokens": 296,
            "green_fraction": 0.9278996865203761,
            "z_score": 1.6611770998290096,
            "p_value": 0.04833894169778824
        },
        "output_with": {
            "num_tokens_scored": 288,
            "num_green_tokens": 278,
            "green_fraction": 0.9652777777777778,
            "z_score": 3.6927939841658337,
            "p_value": 0.00011090185113074415
        }
    },
    {
        "title": "GENSIM: GENERATING ROBOTIC SIMULATION TASKS VIA LARGE LANGUAGE MODELS",
        "abstract": "Collecting large amounts of real-world interaction data to train general robotic policies is often prohibitively expensive, thus motivating the use of simulation data. However, existing methods for data generation have generally focused on scenelevel diversity (e.g., object instances and poses) rather than task-level diversity, due to the human effort required to come up with and verify novel tasks. This has made it challenging for policies trained on simulation data to demonstrate significant task-level generalization. In this paper, we propose to automatically generate rich simulation environments and expert demonstrations by exploiting a large language models\u2019 (LLM) grounding and coding ability. Our approach, dubbed GENSIM, has two modes: goal-directed generation, wherein a target task is given to the LLM and the LLM proposes a task curriculum to solve the target task, and exploratory generation, wherein the LLM bootstraps from previous tasks and iteratively proposes novel tasks that would be helpful in solving more complex tasks. We use GPT4 to expand the existing benchmark by ten times to over 100 tasks, on which we conduct supervised finetuning and evaluate several LLMs including finetuned GPTs and Code Llama on code generation for robotic simulation tasks. Furthermore, we observe that LLMs-generated simulation programs can enhance task-level generalization significantly when used for multitask policy training. We further find that with minimal sim-to-real adaptation, the multitask policies pretrained on GPT4-generated simulation tasks exhibit stronger transfer to unseen long-horizon tasks in the real world and outperform baselines by 25%. 1",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel framework, GenSim, that utilizes large language models (LLMs) to automatically generate rich simulation environments and expert demonstrations for robotic policy training. The framework operates in two distinct modes: goal-directed generation, where a target task is given to the LLM, and exploratory generation, where the LLM bootstraps from previous tasks to propose novel tasks. The authors demonstrate that LLMs can generate high-quality, achievable, and diverse tasks, which can enhance task-level generalization of robotic policies. They evaluate several LLMs, including finetuned GPTs and Code Llama, on code generation for robotic simulation tasks and show that pretraining on LLM-generated simulation tasks can improve real-world generalization capabilities by 25%.\n\nStrengths:\n\n* The paper presents a novel and scalable framework for generating simulation tasks using LLMs, which can augment diverse simulation tasks for robotic policy training.\n* The authors demonstrate the effectiveness of their framework in generating high-quality, achievable, and diverse tasks, which can enhance task-level generalization of robotic policies.\n* The paper provides a thorough evaluation of several LLMs on code generation for robotic simulation tasks and shows that pretraining on LLM-generated simulation tasks can improve real-world generalization capabilities.\n\nWeaknesses:\n\n* The paper relies heavily on a single LLM model, GPT4, and does not explore the robustness of their framework to different LLM models.\n* The evaluation of the framework is limited to a specific task domain (table-top pick-and-place) and does not consider more complex robotic tasks.\n* The paper does not provide a thorough analysis of the limitations of their framework, such as the potential for hallucinations and lack of grounding in physical and geometric details.\n\nSuggestions for Improvement:\n\n* To improve the robustness of the framework, the authors should explore the use of multiple LLM models and evaluate their framework on different task domains.\n* The authors should provide a more thorough analysis of the limitations of their framework, including the potential for hallucinations and lack of grounding in physical and geometric details.\n* The paper should include a more detailed discussion of the potential applications of their framework, such as generating dexterous and complex robotic tasks.\n\nRecommendation:\n\nThe paper presents a novel and scalable framework for generating simulation tasks using LLMs, which can enhance task-level generalization of robotic policies. While the paper has some limitations, it provides a thorough evaluation of their framework and demonstrates its effectiveness in generating high-quality, achievable, and diverse tasks. Therefore, I recommend this paper for publication in a top-tier conference.\n\nRating: 8/10\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\nThe paper proposes a novel framework, GenSim, that utilizes large language models (LLMs) to automatically generate rich simulation environments and expert demonstrations for robotic policy training. The framework operates in two distinct modes: goal-directed generation, where a target task is given to the LLM, and exploratory generation, where the LLM bootstraps from previous tasks to propose novel tasks. The authors demonstrate that LLMs-generated simulation programs can enhance task-level generalization significantly when used for multitask policy training. They also show that pretraining on GPT4-generated simulation tasks exhibits stronger transfer to unseen long-horizon tasks in the real world and outperforms baselines by 25%.\n\nStrengths:\n1. The paper proposes a novel and innovative approach to generating simulation tasks using LLMs, which has the potential to revolutionize robotic policy training.\n2. The authors provide a thorough evaluation of their framework, demonstrating its effectiveness in generating high-quality tasks and improving policy generalization.\n3. The paper highlights the potential of LLMs in scaling simulation tasks and incorporating human feedback, making the task generation process more efficient and scalable.\n\nWeaknesses:\n1. The paper relies heavily on the capabilities of LLMs, which may not be universally applicable to all robotic tasks and environments.\n2. The evaluation metrics used in the paper may not capture all aspects of task generation, such as physical and geometric details, which could lead to hallucinations and basic syntax errors in the generated code.\n3. The paper only explores table-top pick-and-place task generation, and generating dexterous and complex robotic tasks could be more challenging.\n\nSuggestions for Improvement:\n1. Investigate the limitations of LLMs in generating simulation tasks and explore ways to improve their capabilities, such as incorporating domain knowledge and physical constraints.\n2. Develop more comprehensive evaluation metrics that capture the nuances of task generation, including physical and geometric details.\n3. Expand the scope of the paper to include more complex robotic tasks, such as dexterous manipulation and assembly.\n\nRecommendation:\nThe paper presents a novel and innovative approach to generating simulation tasks using LLMs, which has the potential to revolutionize robotic policy training. However, the authors should address the limitations and weaknesses of their framework to make it more robust and applicable to a wider range of robotic tasks and environments. With further development and refinement, GenSim has the potential to become a powerful tool for robotic policy training and simulation.",
        "gr_score_with": 0.9264305177111717,
        "gr_score_without": 0.8918128654970761,
        "output_without": {
            "num_tokens_scored": 342,
            "num_green_tokens": 305,
            "green_fraction": 0.8918128654970761,
            "z_score": -0.5044896195705005,
            "p_value": 0.6930413225634213
        },
        "output_with": {
            "num_tokens_scored": 367,
            "num_green_tokens": 340,
            "green_fraction": 0.9264305177111717,
            "z_score": 1.6879620209194042,
            "p_value": 0.04570925983746274
        }
    },
    {
        "title": "COT3DREF: CHAIN-OF-THOUGHTS DATA-EFFICIENT 3D VISUAL GROUNDING",
        "abstract": "3D visual grounding is the ability to localize objects in 3D scenes conditioned by utterances. Most existing methods devote the referring head to localize the referred object directly, causing failure in complex scenarios. In addition, it does not illustrate how and why the network reaches the final decision. In this paper, we address this question \u201cCan we design an interpretable 3D visual grounding framework that has the potential to mimic the human perception system?\u201d. To this end, we formulate the 3D visual grounding problem as a sequence-to-sequence (Seq2Seq) task by first predicting a chain of anchors and then the final target. Interpretability not only improves the overall performance but also helps us identify failure cases. Following the chain of thoughts approach enables us to decompose the referring task into interpretable intermediate steps, boosting the performance and making our framework extremely data-efficient. Moreover, our proposed framework can be easily integrated into any existing architecture. We validate our approach through comprehensive experiments on the Nr3D, Sr3D, and Scanrefer benchmarks and show consistent performance gains compared to existing methods without requiring manually annotated data. Furthermore, our proposed framework, dubbed CoT3DRef, is significantly data-efficient, whereas on the Sr3D dataset, when trained only on 10% of the data, we match the SOTA performance that trained on the entire data. The code is available at https://cot3dref.github.io/.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel and interpretable framework, CoT3DRef, for 3D visual grounding. The framework formulates the problem of 3D visual grounding from a natural language instruction as a sequence-to-sequence task, predicting a chain of anchor objects that are subsequently utilized to localize the final target object. This sequential approach enhances interpretability and improves overall performance and data efficiency. The framework is data-efficient and outperforms existing methods on the Nr3D and Sr3D datasets when trained on a limited amount of data. The authors also demonstrate the effectiveness of their approach by integrating it into four different baselines and achieving state-of-the-art results on three well-known 3D visual grounding benchmarks.\n\nStrengths:\n\n1. The paper proposes a novel and interpretable framework for 3D visual grounding, which is a significant contribution to the field.\n2. The framework is data-efficient and outperforms existing methods on the Nr3D and Sr3D datasets when trained on a limited amount of data.\n3. The authors demonstrate the effectiveness of their approach by integrating it into four different baselines and achieving state-of-the-art results on three well-known 3D visual grounding benchmarks.\n4. The paper provides a comprehensive analysis of the framework's performance and limitations, including the use of pseudo-labels and the Pathway module.\n\nWeaknesses:\n\n1. The paper relies heavily on pseudo-labels, which may not be accurate and can lead to performance loss on certain datasets.\n2. The Pathway module has limitations, including not handling multi-path scenarios, which may lead to suboptimal performance in certain cases.\n3. The paper does not provide a thorough comparison with other state-of-the-art methods, which makes it difficult to evaluate the framework's performance in a broader context.\n4. The paper assumes that the input utterance is well-formed and does not handle cases where the utterance is ambiguous or contains negations.\n\nSuggestions for Improvement:\n\n1. The authors should investigate alternative methods for collecting pseudo-labels, such as using more advanced natural language processing techniques or incorporating human annotations.\n2. The Pathway module should be modified to handle multi-path scenarios, such as using a graph-based approach to reason about different possibilities.\n3. The paper should provide a more thorough comparison with other state-of-the-art methods, including a detailed analysis of the framework's performance and limitations.\n4. The paper should address the assumption that the input utterance is well-formed and provide a more robust solution for handling ambiguous or negated utterances.\n\nRecommendation:\n\nThe paper proposes a novel and interpretable framework for 3D visual grounding, which is a significant contribution to the field. However, the paper relies heavily on pseudo-labels, which may not be accurate, and the Pathway module has limitations. To improve the framework, the authors should investigate alternative methods for collecting pseudo-labels and modify the Pathway module to handle multi-path scenarios. Additionally, the paper should provide a more thorough comparison with other state-of-the-art methods and address the assumption that the input utterance is well-formed. Overall, the paper is well-written and provides a comprehensive analysis of the framework's performance and limitations.\n\nRecommendation: Accept after revisions.\n\n$$$",
        "peer_review_with_watermark": "$$\nPaper Summary:\n\nThe paper proposes a novel and interpretable framework, CoT3DRef, for 3D visual grounding. The framework formulates the problem as a sequence-to-sequence task, predicting a chain of anchor objects that are subsequently used to localize the final target object. The approach enhances interpretability and improves overall performance and data efficiency. The authors demonstrate the effectiveness of their framework through extensive experiments on three 3D visual grounding benchmarks, achieving state-of-the-art results without requiring any additional manual annotations.\n\nStrengths:\n\n*   The proposed framework, CoT3DRef, is novel and interpretable, providing a clear and logical sequence of steps for 3D visual grounding.\n*   The framework demonstrates excellent performance on three challenging benchmarks, Nr3D, Sr3D, and ScanRefer, achieving state-of-the-art results without requiring any additional manual annotations.\n*   The authors provide a comprehensive analysis of the framework's performance, including ablation studies and comparisons with state-of-the-art methods.\n*   The framework's data efficiency is demonstrated through experiments on limited data, showcasing its potential for real-world applications.\n\nWeaknesses:\n\n*   The accuracy of the pseudo-labels plays a vital role in the overall performance, and a significant accuracy gap is measured between automatically collected pseudo-labels and ground-truth data, contributing to the performance loss observed on the Nr3D dataset.\n*   The pseudo module limitations hinder achieving more gain on Nr3D, and the anchor localization block in the pseudo module is tailored on ScanNet dataset and will need adaptations to be usable on other 3D scene datasets.\n*   The Pathway module limitations do not handle the multi-path scenario, where multiple paths are valid, and a possible solution to handle this limitation implicitly through building a graph that reasons the different possibilities.\n\nSuggestions for Improvement:\n\n*   Enhance the pseudo module performance to reduce the accuracy gap between automatically collected pseudo-labels and ground-truth data.\n*   Adapt the anchor localization block in the pseudo module to be usable on other 3D scene datasets.\n*   Develop a more robust Pathway module that can handle the multi-path scenario and provide a clear and logical sequence of steps for 3D visual grounding.\n\nRecommendation:\n\nThe paper proposes a novel and interpretable framework for 3D visual grounding, demonstrating excellent performance on three challenging benchmarks. While there are some limitations, the framework's data efficiency and potential for real-world applications make it a valuable contribution to the field. I recommend accepting the paper for publication, with the suggestion for improvement to enhance the pseudo module performance and adapt the anchor localization block to other 3D scene datasets.\n\n$$",
        "gr_score_with": 0.9267605633802817,
        "gr_score_without": 0.8967391304347826,
        "output_without": {
            "num_tokens_scored": 368,
            "num_green_tokens": 330,
            "green_fraction": 0.8967391304347826,
            "z_score": -0.20831209918109106,
            "p_value": 0.5825073574574943
        },
        "output_with": {
            "num_tokens_scored": 355,
            "num_green_tokens": 329,
            "green_fraction": 0.9267605633802817,
            "z_score": 1.6808647341732337,
            "p_value": 0.04639459564708004
        }
    },
    {
        "title": "REWARD DESIGN FOR JUSTIFIABLE SEQUENTIAL DECISION-MAKING",
        "abstract": "Equipping agents with the capacity to justify made decisions using supporting evidence represents a cornerstone of accountable decision-making. Furthermore, ensuring that justifications are in line with human expectations and societal norms is vital, especially in high-stakes situations such as healthcare. In this work, we propose the use of a debate-based reward model for reinforcement learning agents, where the outcome of a zero-sum debate game quantifies the justifiability of a decision in a particular state. This reward model is then used to train a justifiable policy, whose decisions can be more easily corroborated with supporting evidence. In the debate game, two argumentative agents take turns providing supporting evidence for two competing decisions. Given the proposed evidence, a proxy of a human judge evaluates which decision is better justified. We demonstrate the potential of our approach in learning policies for prescribing and justifying treatment decisions of septic patients. We show that augmenting the reward with the feedback signal generated by the debate-based reward model yields policies highly favored by the judge when compared to the policy obtained solely from the environment rewards, while hardly sacrificing any performance. Moreover, in terms of the overall performance and justifiability of trained policies, the debate-based feedback is comparable to the feedback obtained from an ideal judge proxy that evaluates decisions using the full information encoded in the state. This suggests that the debate game outputs key information contained in states that is most relevant for evaluating decisions, which in turn substantiates the practicality of combining our approach with human-in-the-loop evaluations. Lastly, we showcase that agents trained via multi-agent debate learn to propose evidence that is resilient to refutations and closely aligns with human preferences.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel approach to designing rewards for reinforcement learning (RL) agents that can justify their decisions using supporting evidence. The authors introduce a debate-based reward model, where two argumentative agents take turns providing supporting evidence for two competing decisions. A proxy of a human judge evaluates which decision is better justified based on the proposed evidence. The authors demonstrate the effectiveness of their approach in learning policies for treating septic patients, showing that the debate-based feedback yields policies highly favored by the judge while hardly sacrificing any performance.\n\nStrengths:\n\n1. The paper proposes a novel and innovative approach to designing rewards for RL agents that can justify their decisions using supporting evidence.\n2. The authors provide a thorough and detailed explanation of their approach, including the formal setup, learning framework, and experiments.\n3. The paper presents a comprehensive evaluation of the effectiveness of the debate-based reward model, including quantitative and qualitative results.\n4. The authors provide a clear and concise description of the experimental setup, including the patient cohort, environment, and evaluation metrics.\n\nWeaknesses:\n\n1. The paper assumes a well-defined argument space, which may not be the case in all domains. The authors acknowledge this limitation and suggest potential alternative approaches.\n2. The paper relies on a proxy of a human judge, which may not accurately capture human preferences and biases.\n3. The authors do not provide a thorough discussion of the potential biases and limitations of the debate-based reward model.\n4. The paper assumes a fixed number of turns in the debate game, which may not be realistic in all scenarios.\n\nSuggestions for Improvement:\n\n1. The authors should provide a more detailed discussion of the potential biases and limitations of the debate-based reward model, including the impact of human biases and preferences.\n2. The paper should include a more thorough evaluation of the effectiveness of the debate-based reward model in different domains and scenarios.\n3. The authors should provide a more detailed explanation of the learning framework and the role of the proxy judge in the debate-based reward model.\n4. The paper should include a more comprehensive discussion of the potential applications and limitations of the debate-based reward model.\n\nRecommendation:\n\nThe paper presents a novel and innovative approach to designing rewards for RL agents that can justify their decisions using supporting evidence. While there are some limitations and weaknesses to the approach, the paper provides a thorough and detailed evaluation of the effectiveness of the debate-based reward model. I recommend acceptance of the paper for publication, with the suggestion that the authors address the limitations and weaknesses mentioned above.\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel approach to designing rewards for reinforcement learning (RL) agents that can justify their decisions using evidence. The authors introduce a debate-based reward model, where two argumentative agents engage in a zero-sum debate game to quantify the justifiability of a decision. The outcome of the debate game is used to train a justifiable policy that can provide evidence to justify its decisions. The authors demonstrate the effectiveness of their approach on a real-world problem of treating septic patients, where they show that the justifiable policy trained using the debate-based reward model yields policies that are highly favored by a human judge when compared to the policy obtained solely from the environment rewards.\n\nStrengths:\n\n1. The paper proposes a novel and innovative approach to designing rewards for RL agents that can justify their decisions using evidence.\n2. The debate-based reward model is a well-designed and effective way to quantify the justifiability of a decision.\n3. The paper provides a comprehensive evaluation of the approach on a real-world problem of treating septic patients, including both quantitative and qualitative evaluation.\n4. The authors provide a thorough analysis of the performance and justifiability of the trained policies, including the effect of the debate coefficient \u03bb on the trade-off between performance and justifiability.\n\nWeaknesses:\n\n1. The paper assumes that the human judge's preferences can be elicited and used to evaluate the justifiability of decisions, which may not always be the case in real-world scenarios.\n2. The debate-based reward model may not be scalable to larger state spaces, as the number of possible evidence sets grows exponentially with the size of the state space.\n3. The paper does not provide a thorough analysis of the robustness of the approach to different types of biases and adversarial attacks.\n4. The paper assumes that the argumentative agents can provide evidence that is resilient to refutations, which may not always be the case in real-world scenarios.\n\nSuggestions for Improvement:\n\n1. The authors should provide a more thorough analysis of the robustness of the approach to different types of biases and adversarial attacks.\n2. The paper should provide a more detailed discussion on how to elicit and use human preferences in real-world scenarios.\n3. The authors should provide a more thorough evaluation of the approach on larger state spaces and more complex decision-making problems.\n4. The paper should provide a more detailed analysis of the trade-off between performance and justifiability in different scenarios.\n\nRecommendation:\n\nThe paper presents a novel and innovative approach to designing rewards for RL agents that can justify their decisions using evidence. While there are some limitations to the approach, the paper provides a thorough evaluation and analysis of the approach on a real-world problem of treating septic patients. The approach has the potential to be applied to a wide range of decision-making problems, including healthcare, finance, and education. Therefore, I recommend accepting the paper for publication.\n\n$$$\nNote: The review is based on the provided paper and does not include any external knowledge or information. The review is written in a standard conference review format and includes a summary, strengths, weaknesses, suggestions for improvement, and a recommendation.",
        "gr_score_with": 0.9384615384615385,
        "gr_score_without": 0.8794788273615635,
        "output_without": {
            "num_tokens_scored": 307,
            "num_green_tokens": 270,
            "green_fraction": 0.8794788273615635,
            "z_score": -1.198334545045815,
            "p_value": 0.8846065984123186
        },
        "output_with": {
            "num_tokens_scored": 390,
            "num_green_tokens": 366,
            "green_fraction": 0.9384615384615385,
            "z_score": 2.532018623437144,
            "p_value": 0.005670398384420182
        }
    },
    {
        "title": "ERAL GEOMETRY FOR KNOWLEDGE DISTILLATION",
        "abstract": "Knowledge distillation aims to train a compact student network using soft supervision from a larger teacher network and hard supervision from ground truths. However, determining an optimal knowledge fusion ratio that balances these supervisory signals remains challenging. Prior methods generally resort to a constant or heuristic-based fusion ratio, which often falls short of a proper balance. In this study, we introduce a novel adaptive method for learning a sample-wise knowledge fusion ratio, exploiting both the correctness of teacher and student, as well as how well the student mimics the teacher on each sample. Our method naturally leads to the intra-sample trilateral geometric relations among the student prediction (S), teacher prediction (T ), and ground truth (G). To counterbalance the impact of outliers, we further extend to the inter-sample relations, incorporating the teacher\u2019s global average prediction (T\u0304 ) for samples within the same class. A simple neural network then learns the implicit mapping from the intraand inter-sample relations to an adaptive, sample-wise knowledge fusion ratio in a bilevel-optimization manner. Our approach provides a simple, practical, and adaptable solution for knowledge distillation that can be employed across various architectures and model sizes. Extensive experiments demonstrate consistent improvements over other loss re-weighting methods on image classification, attack detection, and click-through rate prediction.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel approach named TGeo-KD for learning sample-wise knowledge fusion ratios during knowledge distillation (KD). The authors argue that existing methods for determining the knowledge fusion ratio often rely on heuristic rules or constant values, which may not capture the nuanced dynamics of the knowledge transfer process. To address this limitation, the authors introduce a novel adaptive method that learns a sample-wise knowledge fusion ratio by exploiting both the correctness of the teacher and student, as well as the discrepancy between their predictions. The proposed method, TGeo-KD, leverages the trilateral geometry among the signals from the student, teacher, and ground truth by modeling both intra- and inter-sample geometric relations.\n\nStrengths:\n\n1. The paper presents a well-structured and clear introduction to the problem of knowledge distillation and the limitations of existing methods.\n2. The proposed approach, TGeo-KD, is innovative and well-motivated, leveraging the trilateral geometry among the signals from the student, teacher, and ground truth.\n3. The authors provide extensive experiments across diverse domains, including image classification, attack detection, and click-through rate prediction, demonstrating the consistent superiority of TGeo-KD over other re-weighting methods.\n4. The paper provides a clear and concise explanation of the proposed method, including the bilevel optimization problem and the intra- and inter-sample geometric relations.\n\nWeaknesses:\n\n1. The paper assumes a relatively simple neural network architecture for learning the knowledge fusion ratio, which may not be optimal for all scenarios.\n2. The authors do not provide a thorough analysis of the computational complexity of the proposed method, which may be a concern for large-scale applications.\n3. The paper focuses primarily on image classification tasks and does not provide a comprehensive evaluation of TGeo-KD on other tasks, such as object detection or segmentation.\n4. The authors do not provide a clear explanation of how the proposed method can be extended to handle multiple teachers or students.\n\nSuggestions for Improvement:\n\n1. The authors could provide a more detailed analysis of the computational complexity of the proposed method and discuss potential optimizations.\n2. The paper could benefit from a more comprehensive evaluation of TGeo-KD on a wider range of tasks and datasets.\n3. The authors could provide a clear explanation of how the proposed method can be extended to handle multiple teachers or students.\n4. The paper could benefit from a more detailed discussion of the limitations of the proposed method and potential areas for future research.\n\nRecommendation:\n\nI highly recommend this paper for publication in a top-tier conference or journal in the field of machine learning. The proposed approach, TGeo-KD, is innovative and well-motivated, and the authors provide extensive experiments demonstrating its consistent superiority over other re-weighting methods. However, the authors should address the limitations and suggestions for improvement mentioned above to further strengthen the paper.\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel method named TGeo-KD for learning sample-wise knowledge fusion ratios during knowledge distillation (KD). The method leverages the trilateral geometry among the signals from the student, teacher, and ground truth by modeling both intra- and inter-sample geometric relations. The TGeo-KD method is designed to adaptively learn the knowledge fusion ratio based on the trilateral geometry within the (S, T, G) triplet. The method is evaluated on three different tasks: image classification on CIFAR-100 and ImageNet, attack detection on HIL, and click-through rate prediction on Criteo. The results show that TGeo-KD consistently outperforms other re-weighting methods.\n\nStrengths:\n\n* The paper proposes a novel method for learning sample-wise knowledge fusion ratios during KD.\n* The method leverages the trilateral geometry among the signals from the student, teacher, and ground truth.\n* The method is designed to adaptively learn the knowledge fusion ratio based on the trilateral geometry within the (S, T, G) triplet.\n* The method is evaluated on three different tasks: image classification on CIFAR-100 and ImageNet, attack detection on HIL, and click-through rate prediction on Criteo.\n* The results show that TGeo-KD consistently outperforms other re-weighting methods.\n\nWeaknesses:\n\n* The paper does not provide a clear explanation of the motivation behind the proposed method.\n* The paper does not provide a detailed analysis of the trilateral geometry within the (S, T, G) triplet.\n* The paper does not provide a comparison of the proposed method with other KD methods that do not use trilateral geometry.\n* The paper does not provide a discussion on the limitations of the proposed method.\n* The paper does not provide a clear explanation of the experimental settings and the choice of hyperparameters.\n\nSuggestions for Improvement:\n\n* Provide a clear explanation of the motivation behind the proposed method.\n* Provide a detailed analysis of the trilateral geometry within the (S, T, G) triplet.\n* Compare the proposed method with other KD methods that do not use trilateral geometry.\n* Discuss the limitations of the proposed method.\n* Provide a clear explanation of the experimental settings and the choice of hyperparameters.\n\nRecommendation:\n\nThe paper proposes a novel method for learning sample-wise knowledge fusion ratios during KD. The method leverages the trilateral geometry among the signals from the student, teacher, and ground truth. The results show that TGeo-KD consistently outperforms other re-weighting methods. However, the paper has several weaknesses that need to be addressed. With some improvements, the paper has the potential to make a significant contribution to the field of KD.",
        "gr_score_with": 0.9110169491525424,
        "gr_score_without": 0.8770053475935828,
        "output_without": {
            "num_tokens_scored": 374,
            "num_green_tokens": 328,
            "green_fraction": 0.8770053475935828,
            "z_score": -1.4820964546364568,
            "p_value": 0.9308426839886741
        },
        "output_with": {
            "num_tokens_scored": 236,
            "num_green_tokens": 215,
            "green_fraction": 0.9110169491525424,
            "z_score": 0.5643038302197159,
            "p_value": 0.28627368758976707
        }
    },
    {
        "title": "TAPMO: SHAPE-AWARE MOTION GENERATION OF SKELETON-FREE CHARACTERS",
        "abstract": "Previous motion generation methods are limited to the pre-rigged 3D human model, hindering their applications in the animation of various non-rigged characters. In this work, we present TapMo, a Text-driven Animation Pipeline for synthesizing Motion in a broad spectrum of skeleton-free 3D characters. The pivotal innovation in TapMo is its use of shape deformation-aware features as a condition to guide the diffusion model, thereby enabling the generation of meshspecific motions for various characters. Specifically, TapMo comprises two main components Mesh Handle Predictor and Shape-aware Diffusion Module. Mesh Handle Predictor predicts the skinning weights and clusters mesh vertices into adaptive handles for deformation control, which eliminates the need for traditional skeletal rigging. Shape-aware Motion Diffusion synthesizes motion with mesh-specific adaptations. This module employs text-guided motions and mesh features extracted during the first stage, preserving the geometric integrity of the animations by accounting for the character\u2019s shape and deformation. Trained in a weakly-supervised manner, TapMo can accommodate a multitude of nonhuman meshes, both with and without associated text motions. We demonstrate the effectiveness and generalizability of TapMo through rigorous qualitative and quantitative experiments. Our results reveal that TapMo consistently outperforms existing auto-animation methods, delivering superior-quality animations for both seen or unseen heterogeneous 3D characters. The project page: https://semanticdh.github.io/TapMo.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper presents a novel text-driven animation pipeline called TapMo, which enables the generation of realistic and anthropomorphic motion for a wide range of skeleton-free 3D characters. The pipeline consists of two key components: the Mesh Handle Predictor and the Shape-aware Motion Diffusion. The Mesh Handle Predictor predicts the skinning weights and clusters mesh vertices into adaptive handles for semantic control, while the Shape-aware Motion Diffusion generates text-guided motions considering the specific deformation properties of the mesh. The authors propose a weakly-supervised training strategy for adaptive mesh handle learning and mesh-specific motion learning to train TapMo with limited ground-truth data. The paper demonstrates the effectiveness and generalizability of TapMo through extensive experiments and shows that it achieves state-of-the-art performance compared to baseline methods.\n\nStrengths:\n\n1. The paper presents a novel and comprehensive solution for text-driven animation of skeleton-free 3D characters.\n2. The authors propose a weakly-supervised training strategy for adaptive mesh handle learning and mesh-specific motion learning, which is innovative and effective.\n3. The paper demonstrates the effectiveness and generalizability of TapMo through extensive experiments and shows that it achieves state-of-the-art performance compared to baseline methods.\n4. The authors provide a clear and concise explanation of the proposed method and its components.\n\nWeaknesses:\n\n1. The paper assumes that the input mesh is provided, which may not be the case in practice. The authors should provide more information on how to handle this issue.\n2. The paper does not provide a detailed comparison with other methods that can handle skeleton-free 3D characters.\n3. The authors should provide more information on the computational cost of the proposed method and how it compares to other methods.\n4. The paper assumes that the text description is provided, which may not be the case in practice. The authors should provide more information on how to handle this issue.\n\nSuggestions for Improvement:\n\n1. Provide more information on how to handle the case where the input mesh is not provided.\n2. Provide a detailed comparison with other methods that can handle skeleton-free 3D characters.\n3. Provide more information on the computational cost of the proposed method and how it compares to other methods.\n4. Provide more information on how to handle the case where the text description is not provided.\n5. Consider providing more information on the robustness of the proposed method to different types of meshes and text descriptions.\n\nRecommendation:\n\nThe paper presents a novel and comprehensive solution for text-driven animation of skeleton-free 3D characters. The authors propose a weakly-supervised training strategy for adaptive mesh handle learning and mesh-specific motion learning, which is innovative and effective. The paper demonstrates the effectiveness and generalizability of TapMo through extensive experiments and shows that it achieves state-of-the-art performance compared to baseline methods. However, the paper assumes that the input mesh is provided, which may not be the case in practice. The authors should provide more information on how to handle this issue. Overall, the paper is well-written and provides a clear and concise explanation of the proposed method and its components. I recommend this paper for publication in the conference.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper presents a novel text-driven animation pipeline called TapMo, which enables the generation of realistic and anthropomorphic motion for a wide range of skeleton-free 3D characters. TapMo consists of two key components: the Mesh Handle Predictor and the Shape-aware Motion Diffusion. The Mesh Handle Predictor predicts the skinning weights and clusters mesh vertices into adaptive handles for semantic control, while the Shape-aware Motion Diffusion generates text-guided motions considering the specific deformation properties of the mesh. To train TapMo with limited ground-truth data, the authors propose a weakly-supervised training strategy for adaptive mesh handle learning and mesh-specific motion learning. The authors conduct extensive experiments to validate the effectiveness of TapMo and show that it achieves state-of-the-art performance compared to baseline methods.\n\nStrengths:\n\n1. TapMo is a novel and comprehensive solution for text-driven animation of skeleton-free 3D characters, which has the potential to democratize animation creation.\n2. The authors propose a weakly-supervised training strategy for adaptive mesh handle learning and mesh-specific motion learning, which is essential for training TapMo with limited ground-truth data.\n3. The Shape-aware Motion Diffusion module is designed to generate text-guided motions considering the specific deformation properties of the mesh, which ensures coherent and plausible character animation without introducing mesh distortion.\n4. The authors conduct extensive experiments to validate the effectiveness of TapMo and show that it achieves state-of-the-art performance compared to baseline methods.\n\nWeaknesses:\n\n1. The paper assumes that the input mesh is already pre-processed and cleaned, which may not be the case in real-world scenarios.\n2. The authors do not provide a detailed analysis of the computational cost of TapMo, which is essential for its practical deployment.\n3. The paper focuses primarily on the qualitative results of TapMo, and the quantitative results could be more comprehensive.\n4. The authors do not provide a clear explanation of how the Mesh Handle Predictor is able to predict the skinning weights and cluster mesh vertices into adaptive handles.\n\nSuggestions for Improvement:\n\n1. Provide a detailed analysis of the computational cost of TapMo and its practical deployment.\n2. Conduct more comprehensive experiments to validate the effectiveness of TapMo, including quantitative results.\n3. Provide a clear explanation of how the Mesh Handle Predictor is able to predict the skinning weights and cluster mesh vertices into adaptive handles.\n4. Consider adding more diverse and challenging scenarios to the experiments to further evaluate the robustness and generalizability of TapMo.\n\nRecommendation:\n\nThe paper presents a novel and comprehensive solution for text-driven animation of skeleton-free 3D characters, which has the potential to democratize animation creation. However, there are some weaknesses and areas for improvement that need to be addressed. With further refinement and improvement, TapMo has the potential to become a state-of-the-art solution for text-driven animation of skeleton-free 3D characters.\n\n$$$",
        "gr_score_with": 0.956140350877193,
        "gr_score_without": 0.9470198675496688,
        "output_without": {
            "num_tokens_scored": 302,
            "num_green_tokens": 286,
            "green_fraction": 0.9470198675496688,
            "z_score": 2.7238701703045543,
            "p_value": 0.003226093239619197
        },
        "output_with": {
            "num_tokens_scored": 342,
            "num_green_tokens": 327,
            "green_fraction": 0.956140350877193,
            "z_score": 3.4608679330729646,
            "p_value": 0.0002692184445651806
        }
    },
    {
        "title": "DiLu : A Knowledge-Driven Approach to Autonomous Driving with Large Language Models",
        "abstract": "Recent advancements in autonomous driving have relied on data-driven approaches, which are widely adopted but face challenges including dataset bias, overfitting, and uninterpretability. Drawing inspiration from the knowledge-driven nature of human driving, we explore the question of how to instill similar capabilities into autonomous driving systems and summarize a paradigm that integrates an interactive environment, a driver agent, as well as a memory component to address this question. Leveraging large language models (LLMs) with emergent abilities, we propose the DiLu framework, which combines a Reasoning and a Reflection module to enable the system to perform decision-making based on common-sense knowledge and evolve continuously. Extensive experiments prove DiLu\u2019s capability to accumulate experience and demonstrate a significant advantage in generalization ability over reinforcement learning-based methods. Moreover, DiLu is able to directly acquire experiences from real-world datasets which highlights its potential to be deployed on practical autonomous driving systems. To the best of our knowledge, we are the first to leverage knowledge-driven capability in decision-making for autonomous vehicles. Through the proposed DiLu framework, LLM is strengthened to apply knowledge and to reason causally in the autonomous driving domain. Project page: https://pjlab-adg.github.io/DiLu/",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel framework called DiLu, which integrates an interactive environment, a driver agent, and a memory component to address the challenges of autonomous driving. DiLu leverages large language models (LLMs) to enable the system to perform decision-making based on common-sense knowledge and evolve continuously. The framework consists of four core modules: Environment, Reasoning, Reflection, and Memory. The Reasoning module utilizes the experiences derived from the Memory module and the common-sense knowledge of the LLM to perform decision-making for the current traffic scenario. The Reflection module assesses past decision sequences, categorizing them as either safe or unsafe, and updates the Memory module with refined decisions. The authors conduct extensive experiments to demonstrate the effectiveness of DiLu in accumulating experience, generalization ability, and transformation ability.\n\nStrengths:\n\n1. The paper proposes a novel and innovative approach to autonomous driving by leveraging LLMs and knowledge-driven capabilities.\n2. The framework is well-structured, and the authors provide a clear explanation of the Reasoning and Reflection modules.\n3. The experiments are thorough, and the authors provide a comprehensive comparison with the state-of-the-art RL-based method.\n4. The paper highlights the importance of generalization and transformation ability in autonomous driving systems.\n\nWeaknesses:\n\n1. The paper lacks a clear explanation of how the LLM is trained and fine-tuned for the autonomous driving task.\n2. The authors do not provide a detailed analysis of the decision-making latency and hallucinations generated by LLMs.\n3. The paper assumes that the LLM has access to a vast amount of common-sense knowledge, which may not be feasible in real-world scenarios.\n4. The authors do not provide a clear comparison with other knowledge-driven approaches in autonomous driving.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed explanation of the LLM training and fine-tuning process.\n2. Conduct a more thorough analysis of the decision-making latency and hallucinations generated by LLMs.\n3. Consider incorporating other knowledge-driven approaches in autonomous driving for a more comprehensive comparison.\n4. Provide a clear explanation of how the framework can be scaled up for real-world applications.\n\nRecommendation:\n\nThe paper proposes a novel and innovative approach to autonomous driving, and the authors provide a clear explanation of the framework. However, the paper lacks a clear explanation of the LLM training and fine-tuning process, and the authors do not provide a detailed analysis of the decision-making latency and hallucinations generated by LLMs. With some modifications and improvements, the paper can be a strong contribution to the field of autonomous driving.\n\nRating: 7/10\n\nRecommendation for Publication: Accept after revisions.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel framework called DiLu, which integrates an interactive environment, a driver agent, and a memory component to address the challenges of autonomous driving. DiLu leverages large language models (LLMs) with emergent abilities to facilitate reasoning and reflection processes. The framework consists of four core modules: Environment, Reasoning, Reflection, and Memory. The Reasoning module utilizes the experiences derived from the Memory module and the common-sense knowledge of the LLM to perform decision-making for the current traffic scenario. The Reflection module continuously learns from past driving experiences and accumulates valuable experiences to enrich the Memory module.\n\nStrengths:\n\n1. The paper presents a novel knowledge-driven approach to autonomous driving, which is a significant departure from traditional data-driven methods.\n2. The DiLu framework is well-structured, and the authors provide a clear explanation of each module's functionality.\n3. The experimental results demonstrate the effectiveness of DiLu in accumulating experience and exhibiting strong generalization ability compared to the SOTA RL-based method.\n4. The paper provides a comprehensive literature review of related works, including recent advancements in LLMs and their applications in autonomous driving.\n\nWeaknesses:\n\n1. The paper relies heavily on the performance of LLMs, which may not be robust in all scenarios, especially when faced with novel or ambiguous situations.\n2. The authors do not provide a thorough evaluation of the framework's performance in real-world scenarios, which is essential for its deployment in practical autonomous driving systems.\n3. The decision-making latency of DiLu is relatively high, which may not be suitable for real-time autonomous driving applications.\n4. The paper does not provide a clear explanation of how the framework handles edge cases, such as sudden changes in the environment or unexpected events.\n\nSuggestions for Improvement:\n\n1. The authors should provide a more comprehensive evaluation of DiLu's performance in real-world scenarios, including its robustness in handling novel or ambiguous situations.\n2. The framework should be modified to reduce the decision-making latency, which is essential for real-time autonomous driving applications.\n3. The authors should provide a more detailed explanation of how the framework handles edge cases, such as sudden changes in the environment or unexpected events.\n4. The paper should include more experiments on the generalization ability of DiLu in different environments, including its performance in scenarios with varying traffic density and lane configurations.\n\nRecommendation:\n\nThe paper presents a novel knowledge-driven approach to autonomous driving, which has the potential to overcome the limitations of traditional data-driven methods. The DiLu framework is well-structured, and the authors provide a clear explanation of each module's functionality. However, the paper relies heavily on the performance of LLMs, which may not be robust in all scenarios. Therefore, I recommend that the authors provide a more comprehensive evaluation of DiLu's performance in real-world scenarios and modify the framework to reduce the decision-making latency.",
        "gr_score_with": 0.9018567639257294,
        "gr_score_without": 0.886039886039886,
        "output_without": {
            "num_tokens_scored": 351,
            "num_green_tokens": 311,
            "green_fraction": 0.886039886039886,
            "z_score": -0.8716019894395989,
            "p_value": 0.8082872275014561
        },
        "output_with": {
            "num_tokens_scored": 377,
            "num_green_tokens": 340,
            "green_fraction": 0.9018567639257294,
            "z_score": 0.12037296349967683,
            "p_value": 0.45209385382657574
        }
    }
]